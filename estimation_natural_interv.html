<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Modern Causal Mediation Analysis - 5&nbsp; Construction of G-computation and weighted estimators for the NDE: The case of the natural direct effect</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./estimation_walkthrough.html" rel="next">
<link href="./estimation_prelims.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><script>
  MathJax = {
    tex: {
      tags: 'ams',  // should be 'ams', 'none', or 'all'
      macros: {
        E: '{\\mathbb{E}}',
        V: '{\\mathbb{V}}',
        P: '{\\mathsf{P}}',
        M: '{\\mathsf{M}}',
        Pr: '{\\mathbb{P}}',
        R: '{\\mathbb{R}}',
        I: '{\\mathbb{I}}',
        1: '{\\mathbb{1}}',
        D: '{\\mathcal{D}}',
        F: '{\\mathcal{F}}',
        M: '{\\mathcal{M}}',
        C: '{\\mathcal{C}}',
        G: '{\\mathcal{G}}',
        X: '{\\mathcal{X}}',
        Z: '{\\mathcal{Z}}',
        Hold: '{\\mathcal{H}}',
        lik: '{\\mathcal{L}}',
        logit: '{\\operatorname{logit}}',
        expit: '{\\operatorname{expit}}',
        argmin: '{\\operatorname*{arg\\,min}}',
        argmax: '{\\operatorname*{arg\\,max}}',
        indep: '{\\perp\\!\\!\\!\\perp}',
        notindep: '{\\centernot{\\perp\\!\\!\\!\\perp}}',
        coloneqq: '{\\mathrel{\\vcenter{:}}=}',
        iid: '{\\,\\, \\mathbin{\\overset{\\text{iid}}{\\sim}} \\,\\,}',
        asto: '{\\mathbin{\\underset{a.s.}{\\to}}}',
        pto: '{\\mathbin{\\underset{p}{\\to}}}',
        dto: '{\\mathbin{\\underset{d}{\\to}}}'
      }
    }
  };
</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./estimation_natural_interv.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Construction of G-computation and weighted estimators for the NDE: The case of the natural direct effect</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modern Causal Mediation Analysis</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/nhejazi/causal_mediation_workshops/" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Toggle reader mode">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome!</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Causal mediation analysis intro</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./effects_defn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Types of path-specific causal mediation effects</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how_to_choose.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">How to choose an estimand: Real-world example</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation_prelims.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Estimation preliminaries: review of doubly robust estimators for the average treatment effect</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation_natural_interv.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Construction of G-computation and weighted estimators for the NDE: The case of the natural direct effect</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation_walkthrough.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><code>R</code> packages for estimation of the causal (in)direct effects</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./longitudinal.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Mediation with time-varying treatments, mediators, and covariates</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appx_additional_readings.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Appendix: Additional topics of interest</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appx_stochastic_effects.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Appendix: Stochastic direct and indirect effects</span></span></a>
  </div>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">Contents</h2>
   
  <ul class="collapse">
<li><a href="#recap-of-definition-and-identification-of-the-natural-direct-effect" id="toc-recap-of-definition-and-identification-of-the-natural-direct-effect" class="nav-link active" data-scroll-target="#recap-of-definition-and-identification-of-the-natural-direct-effect"><span class="header-section-number">5.1</span> Recap of definition and identification of the natural direct effect</a></li>
  <li><a href="#from-causal-to-statistical-quantities" id="toc-from-causal-to-statistical-quantities" class="nav-link" data-scroll-target="#from-causal-to-statistical-quantities"><span class="header-section-number">5.2</span> From causal to statistical quantities</a></li>
  <li><a href="#computing-identification-formulas-if-you-know-the-true-distribution" id="toc-computing-identification-formulas-if-you-know-the-true-distribution" class="nav-link" data-scroll-target="#computing-identification-formulas-if-you-know-the-true-distribution"><span class="header-section-number">5.3</span> Computing identification formulas if you know the true distribution</a></li>
  <li><a href="#plug-in-a.k.a-g-computation-estimator" id="toc-plug-in-a.k.a-g-computation-estimator" class="nav-link" data-scroll-target="#plug-in-a.k.a-g-computation-estimator"><span class="header-section-number">5.4</span> Plug-in (a.k.a g-computation) estimator</a></li>
  <li><a href="#first-weighted-estimator-akin-to-inverse-probability-weighted" id="toc-first-weighted-estimator-akin-to-inverse-probability-weighted" class="nav-link" data-scroll-target="#first-weighted-estimator-akin-to-inverse-probability-weighted"><span class="header-section-number">5.5</span> First weighted estimator (akin to inverse probability weighted)</a></li>
  <li><a href="#second-weighted-estimator" id="toc-second-weighted-estimator" class="nav-link" data-scroll-target="#second-weighted-estimator"><span class="header-section-number">5.6</span> Second weighted estimator</a></li>
  <li><a href="#how-can-g-estimation-and-weighted-estimation-be-implemented-in-practice" id="toc-how-can-g-estimation-and-weighted-estimation-be-implemented-in-practice" class="nav-link" data-scroll-target="#how-can-g-estimation-and-weighted-estimation-be-implemented-in-practice"><span class="header-section-number">5.7</span> How can g-estimation and weighted estimation be implemented in practice?</a></li>
  <li><a href="#pros-and-cons-of-g-computation-and-weighting-parametric-models" id="toc-pros-and-cons-of-g-computation-and-weighting-parametric-models" class="nav-link" data-scroll-target="#pros-and-cons-of-g-computation-and-weighting-parametric-models"><span class="header-section-number">5.8</span> Pros and cons of G-computation and weighting parametric models</a></li>
  <li><a href="#an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect" id="toc-an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect" class="nav-link" data-scroll-target="#an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect"><span class="header-section-number">5.9</span> An example of the bias of a g-computation estimator of the natural direct effect</a></li>
  <li><a href="#pros-and-cons-of-g-computation-or-weighting-with-data-adaptive-regression" id="toc-pros-and-cons-of-g-computation-or-weighting-with-data-adaptive-regression" class="nav-link" data-scroll-target="#pros-and-cons-of-g-computation-or-weighting-with-data-adaptive-regression"><span class="header-section-number">5.10</span> Pros and cons of G-computation or weighting with data-adaptive regression</a></li>
  <li><a href="#solution-to-these-problems-robust-semiparametric-efficient-estimation" id="toc-solution-to-these-problems-robust-semiparametric-efficient-estimation" class="nav-link" data-scroll-target="#solution-to-these-problems-robust-semiparametric-efficient-estimation"><span class="header-section-number">5.11</span> Solution to these problems: robust semiparametric efficient estimation</a></li>
  <li>
<a href="#construction-of-a-semiparametric-efficient-estimator-for-the-nde-a.k.a.-the-one-step-estimator" id="toc-construction-of-a-semiparametric-efficient-estimator-for-the-nde-a.k.a.-the-one-step-estimator" class="nav-link" data-scroll-target="#construction-of-a-semiparametric-efficient-estimator-for-the-nde-a.k.a.-the-one-step-estimator"><span class="header-section-number">6</span> Construction of a semiparametric efficient estimator for the NDE (a.k.a. the one-step estimator)</a>
  <ul class="collapse">
<li><a href="#how-to-compute-the-one-step-estimator-akin-to-augmented-ipw" id="toc-how-to-compute-the-one-step-estimator-akin-to-augmented-ipw" class="nav-link" data-scroll-target="#how-to-compute-the-one-step-estimator-akin-to-augmented-ipw"><span class="header-section-number">6.1</span> How to compute the one-step estimator (akin to Augmented IPW)</a></li>
  <li><a href="#performance-of-the-one-step-estimator-in-a-small-simulation-study" id="toc-performance-of-the-one-step-estimator-in-a-small-simulation-study" class="nav-link" data-scroll-target="#performance-of-the-one-step-estimator-in-a-small-simulation-study"><span class="header-section-number">6.2</span> Performance of the one-step estimator in a small simulation study</a></li>
  <li><a href="#a-note-about-targeted-minimum-loss-based-estimation-tmle" id="toc-a-note-about-targeted-minimum-loss-based-estimation-tmle" class="nav-link" data-scroll-target="#a-note-about-targeted-minimum-loss-based-estimation-tmle"><span class="header-section-number">6.3</span> A note about targeted minimum loss-based estimation (TMLE)</a></li>
  <li><a href="#a-note-about-cross-fitting" id="toc-a-note-about-cross-fitting" class="nav-link" data-scroll-target="#a-note-about-cross-fitting"><span class="header-section-number">6.4</span> A note about cross-fitting</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul class="collapse"><li><a href="https://github.com/nhejazi/causal_mediation_workshops/edit/master/estimation_natural_interv.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nhejazi/causal_mediation_workshops/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Construction of G-computation and weighted estimators for the NDE: The case of the natural direct effect</span>
</h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>- The project is out-of-sync -- use `renv::status()` for details.</code></pre>
</div>
</div>
<section id="recap-of-definition-and-identification-of-the-natural-direct-effect" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="recap-of-definition-and-identification-of-the-natural-direct-effect">
<span class="header-section-number">5.1</span> Recap of definition and identification of the natural direct effect</h2>
<p>Recall:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource tex number-lines code-with-copy"><code class="sourceCode latex"><span id="cb2-1"><a href="#cb2-1"></a><span class="fu">\dimendef\prevdepth</span>=0</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="fu">\pgfdeclarelayer</span>{background}</span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="fu">\pgfsetlayers</span>{background,main}</span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="fu">\usetikzlibrary</span>{arrows,positioning}</span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="fu">\tikzset</span>{</span>
<span id="cb2-6"><a href="#cb2-6"></a>&gt;=stealth',</span>
<span id="cb2-7"><a href="#cb2-7"></a>punkt/.style={</span>
<span id="cb2-8"><a href="#cb2-8"></a>rectangle,</span>
<span id="cb2-9"><a href="#cb2-9"></a>rounded corners,</span>
<span id="cb2-10"><a href="#cb2-10"></a>draw=black, very thick,</span>
<span id="cb2-11"><a href="#cb2-11"></a>text width=6.5em,</span>
<span id="cb2-12"><a href="#cb2-12"></a>minimum height=2em,</span>
<span id="cb2-13"><a href="#cb2-13"></a>text centered},</span>
<span id="cb2-14"><a href="#cb2-14"></a>pil/.style={</span>
<span id="cb2-15"><a href="#cb2-15"></a>-&gt;,</span>
<span id="cb2-16"><a href="#cb2-16"></a>thick,</span>
<span id="cb2-17"><a href="#cb2-17"></a>shorten &lt;=2pt,</span>
<span id="cb2-18"><a href="#cb2-18"></a>shorten &gt;=2pt,}</span>
<span id="cb2-19"><a href="#cb2-19"></a>}</span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="fu">\newcommand</span>{<span class="ex">\Vertex</span>}[2]</span>
<span id="cb2-21"><a href="#cb2-21"></a>{<span class="fu">\node</span>[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {<span class="ss">$#2$</span>};</span>
<span id="cb2-22"><a href="#cb2-22"></a>}</span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="fu">\newcommand</span>{<span class="ex">\VertexR</span>}[2]</span>
<span id="cb2-24"><a href="#cb2-24"></a>{<span class="fu">\node</span>[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {<span class="ss">$#2$</span>};</span>
<span id="cb2-25"><a href="#cb2-25"></a>}</span>
<span id="cb2-26"><a href="#cb2-26"></a><span class="fu">\newcommand</span>{<span class="ex">\ArrowR</span>}[3]</span>
<span id="cb2-27"><a href="#cb2-27"></a>{ <span class="kw">\begin</span>{<span class="ex">pgfonlayer</span>}{background}</span>
<span id="cb2-28"><a href="#cb2-28"></a><span class="fu">\draw</span>[-&gt;,#3] (#1) to[bend right=30] (#2);</span>
<span id="cb2-29"><a href="#cb2-29"></a><span class="kw">\end</span>{<span class="ex">pgfonlayer</span>}</span>
<span id="cb2-30"><a href="#cb2-30"></a>}</span>
<span id="cb2-31"><a href="#cb2-31"></a><span class="fu">\newcommand</span>{<span class="ex">\ArrowL</span>}[3]</span>
<span id="cb2-32"><a href="#cb2-32"></a>{ <span class="kw">\begin</span>{<span class="ex">pgfonlayer</span>}{background}</span>
<span id="cb2-33"><a href="#cb2-33"></a><span class="fu">\draw</span>[-&gt;,#3] (#1) to[bend left=45] (#2);</span>
<span id="cb2-34"><a href="#cb2-34"></a><span class="kw">\end</span>{<span class="ex">pgfonlayer</span>}</span>
<span id="cb2-35"><a href="#cb2-35"></a>}</span>
<span id="cb2-36"><a href="#cb2-36"></a><span class="fu">\newcommand</span>{<span class="ex">\EdgeL</span>}[3]</span>
<span id="cb2-37"><a href="#cb2-37"></a>{ <span class="kw">\begin</span>{<span class="ex">pgfonlayer</span>}{background}</span>
<span id="cb2-38"><a href="#cb2-38"></a><span class="fu">\draw</span>[dashed,#3] (#1) to[bend right=-45] (#2);</span>
<span id="cb2-39"><a href="#cb2-39"></a><span class="kw">\end</span>{<span class="ex">pgfonlayer</span>}</span>
<span id="cb2-40"><a href="#cb2-40"></a>}</span>
<span id="cb2-41"><a href="#cb2-41"></a><span class="fu">\newcommand</span>{<span class="ex">\Arrow</span>}[3]</span>
<span id="cb2-42"><a href="#cb2-42"></a>{ <span class="kw">\begin</span>{<span class="ex">pgfonlayer</span>}{background}</span>
<span id="cb2-43"><a href="#cb2-43"></a><span class="fu">\draw</span>[-&gt;,#3] (#1) -- +(#2);</span>
<span id="cb2-44"><a href="#cb2-44"></a><span class="kw">\end</span>{<span class="ex">pgfonlayer</span>}</span>
<span id="cb2-45"><a href="#cb2-45"></a>}</span>
<span id="cb2-46"><a href="#cb2-46"></a><span class="kw">\begin</span>{<span class="ex">tikzpicture</span>}</span>
<span id="cb2-47"><a href="#cb2-47"></a>  <span class="fu">\Vertex</span>{-4, 0}{W}</span>
<span id="cb2-48"><a href="#cb2-48"></a>  <span class="fu">\Vertex</span>{0, 0}{M}</span>
<span id="cb2-49"><a href="#cb2-49"></a>  <span class="fu">\Vertex</span>{-2, 0}{A}</span>
<span id="cb2-50"><a href="#cb2-50"></a>  <span class="fu">\Vertex</span>{2, 0}{Y}</span>
<span id="cb2-51"><a href="#cb2-51"></a>  <span class="fu">\Arrow</span>{W}{A}{black}</span>
<span id="cb2-52"><a href="#cb2-52"></a>  <span class="fu">\Arrow</span>{A}{M}{black}</span>
<span id="cb2-53"><a href="#cb2-53"></a>  <span class="fu">\Arrow</span>{M}{Y}{black}</span>
<span id="cb2-54"><a href="#cb2-54"></a>  <span class="fu">\ArrowL</span>{W}{Y}{black}</span>
<span id="cb2-55"><a href="#cb2-55"></a>  <span class="fu">\ArrowL</span>{A}{Y}{black}</span>
<span id="cb2-56"><a href="#cb2-56"></a>  <span class="fu">\ArrowL</span>{W}{M}{black}</span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="kw">\end</span>{<span class="ex">tikzpicture</span>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="estimation_natural_interv_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="768"></p>
<figcaption>Directed acyclic graph under <em>no intermediate confounders</em> of the mediator-outcome relation affected by treatment</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>Assuming a binary <span class="math inline">\(A\)</span>, we define the natural direct effect as: <span class="math inline">\(\text{NDE} = \E(Y_{1,M_{0}} - Y_{0,M_{0}})\)</span>.</li>
<li>and the natural indirect effect as: <span class="math inline">\(\text{NIE} = \E(Y_{1,M_{1}} - Y_{1,M_{0}})\)</span>.</li>
<li>The observed data is <span class="math inline">\(O = (W, A, M, Y)\)</span>
</li>
</ul>
<p>This SCM is represented in the above DAG and the following causal models: <span class="math display">\[\begin{align*}
  W &amp; = f_W(U_W) \\
  A &amp; = f_A(W, U_A) \\
  M &amp; = f_M(W, A, U_M) \\
  Y &amp; = f_Y(W, A, M, U_Y),
\end{align*}\]</span> where <span class="math inline">\((U_W, U_A,U_M, U_Y)\)</span> are exogenous random errors.</p>
<p>Recall that we need to assume the following to identify the above causal effects from our observed data:</p>
<ul>
<li><span class="math inline">\(A \indep Y_{a,m} \mid W\)</span></li>
<li><span class="math inline">\(M \indep Y_{a,m} \mid W, A\)</span></li>
<li><span class="math inline">\(A \indep M_a \mid W\)</span></li>
<li><span class="math inline">\(M_0 \indep Y_{1,m} \mid W\)</span></li>
<li>and positivity assumptions</li>
</ul>
<p>Then, the NDE is identified as <span class="math display">\[
    \psi(\P) = \E[\E\{\E(Y \mid A=1, M, W) - \E(Y \mid A=0, M, W) \mid A=0,W\}]
  \]</span></p>
</section><section id="from-causal-to-statistical-quantities" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="from-causal-to-statistical-quantities">
<span class="header-section-number">5.2</span> From causal to statistical quantities</h2>
<ul>
<li>We have arrived at identification formulas that express quantities that we care about in terms of observable quantities</li>
<li>That is, these formulas express what would have happened in hypothetical worlds in terms of quantities observable in this world.</li>
<li>This required <strong>causal assumptions</strong>
<ul>
<li>Many of these assumptions are empirically unverifiable</li>
<li>We saw an example where we could relax the cross-world assumption, at the cost of changing the parameter interpretation (when we introduced randomized interventional direct and indirect effects).</li>
<li>We also include an extra section at the end about <strong>stochastic</strong> randomized interventional direct and indirect effects, which allow us to relax the positivity assumption, also at the cost of changing the parameter interpretation.</li>
</ul>
</li>
<li>We are now ready to tackle the estimation problem, i.e., how do we best learn the value of quantities that are observable?</li>
<li>The resulting estimation problem can be tackled using <strong>statistical assumptions</strong> of various degrees of strength
<ul>
<li>Most of these assumptions are verifiable (e.g., a linear model)</li>
<li>Thus, most are unnecessary (except for convenience)</li>
<li>We have worked hard to try to satisfy the required causal assumptions</li>
<li>This is not the time to introduce unnecessary statistical assumptions</li>
<li>The estimation approach we will minimizes reliance on these statistical assumptions.</li>
</ul>
</li>
</ul></section><section id="computing-identification-formulas-if-you-know-the-true-distribution" class="level2" data-number="5.3"><h2 data-number="5.3" class="anchored" data-anchor-id="computing-identification-formulas-if-you-know-the-true-distribution">
<span class="header-section-number">5.3</span> Computing identification formulas if you know the true distribution</h2>
<ul>
<li>The mediation parameters that we consider can be seen as a function of the joint probability distribution of observed data <span class="math inline">\(O=(W,A,Z,M,Y)\)</span>
</li>
<li>For example, under identifiability assumptions the natural direct effect is equal to <span class="math display">\[
  \psi(\P) = \E[\color{Goldenrod}{\E\{\color{ForestGreen}
    {\E(Y \mid A=1, M, W) - \E(Y \mid A=0, M, W)} \mid A=0, W \}}]
\]</span>
</li>
<li>The notation <span class="math inline">\(\psi(\P)\)</span> means that the parameter is a function of <span class="math inline">\(\P\)</span> – in other words, that it is a function of this joint probability distribution</li>
<li>This means that we can compute it for any distribution <span class="math inline">\(\P\)</span>
</li>
<li>For example, if we know the true <span class="math inline">\(\P(W,A,M,Y)\)</span>, we can comnpute the true value of the parameter by:
<ul>
<li>Computing the conditional expectation <span class="math inline">\(\E(Y\mid A=1,M=m,W=w)\)</span> for all values <span class="math inline">\((m,w)\)</span>
</li>
<li>Computing the conditional expectation <span class="math inline">\(\E(Y\mid A=0,M=m,W=w)\)</span> for all values <span class="math inline">\((m,w)\)</span>
</li>
<li>Computing the probability <span class="math inline">\(\P(M=m\mid A=0,W=w)\)</span> for all values <span class="math inline">\((m,w)\)</span>
</li>
<li>Compute <span class="math display">\[\begin{align*}
  \color{Goldenrod}{\E\{}&amp;\color{ForestGreen}{\E(Y \mid A=1, M, W) -
    \E(Y \mid A=0, M, W)}\color{Goldenrod}{\mid A=0,W\}} =\\
  &amp;\color{Goldenrod}{\sum_m\color{ForestGreen}{\{\E(Y \mid A=1, m, w) -
    \E(Y \mid A=0, m, w)\}} \P(M=m\mid A=0, W=w)}
\end{align*}\]</span>
</li>
<li>Computing the probability <span class="math inline">\(\P(W=w)\)</span> for all values <span class="math inline">\(w\)</span>
</li>
<li>Computing the mean over all values <span class="math inline">\(w\)</span>
</li>
</ul>
</li>
</ul></section><section id="plug-in-a.k.a-g-computation-estimator" class="level2" data-number="5.4"><h2 data-number="5.4" class="anchored" data-anchor-id="plug-in-a.k.a-g-computation-estimator">
<span class="header-section-number">5.4</span> Plug-in (a.k.a g-computation) estimator</h2>
<p>The above is how you would compute the <em>true value</em> <strong>if you know</strong> the true distribution <span class="math inline">\(\P\)</span></p>
<ul>
<li>This is exactly what we did in our R examples before</li>
<li>But we can use the same logic for estimation:
<ul>
<li>Fit a regression to estimate, say <span class="math inline">\(\hat\E(Y\mid A=1,M=m,W=w)\)</span>
</li>
<li>Fit a regression to estimate, say <span class="math inline">\(\hat\E(Y\mid A=0,M=m,W=w)\)</span>
</li>
<li>Fit a regression to estimate, say <span class="math inline">\(\hat\P(M=m\mid A=0,W=w)\)</span>
</li>
<li>Estimate <span class="math inline">\(\P(W=w)\)</span> with the empirical distribution</li>
<li>Evaluate <span class="math display">\[
  \psi(\hat\P) = \hat{\E}[\color{RoyalBlue}{
    \hat{\E}\{\color{Goldenrod}{\hat\E(Y \mid A=1, M, W) -
    \hat{\E}(Y \mid A=0, M, W)}\mid A=0,W\}}]
\]</span>
</li>
</ul>
</li>
<li>This is known as the G-computation estimator.</li>
</ul></section><section id="first-weighted-estimator-akin-to-inverse-probability-weighted" class="level2" data-number="5.5"><h2 data-number="5.5" class="anchored" data-anchor-id="first-weighted-estimator-akin-to-inverse-probability-weighted">
<span class="header-section-number">5.5</span> First weighted estimator (akin to inverse probability weighted)</h2>
<ul>
<li>An alternative expression of the parameter functional (for the NDE) is given by <span class="math display">\[
  \E \bigg[\color{RoyalBlue}{\bigg\{ \frac{\I(A=1)}{\P(A=1\mid W)}
  \frac{\P(M\mid A=0,W)}{\P(M\mid A=1,W)} -
  \frac{\I(A=0)}{\P(A=0\mid W)}\bigg\}} \times \color{Goldenrod}{Y}\bigg]
\]</span>
</li>
<li>Thus, you can also construct a weighted estimator as <span class="math display">\[
  \frac{1}{n} \sum_{i=1}^n \bigg[\color{RoyalBlue}{\bigg\{
  \frac{\I(A_i=1)}{\hat{\P}(A_i=1\mid W_i)}
  \frac{\hat{\P}(M_i\mid A_i=0,W_i)}{\hat{\P}(M_i\mid A_i=1, W_i)} -
  \frac{\I(A_i=0)}{\hat{\P}(A_i=0\mid W_i)}\bigg\}} \times
  \color{Goldenrod}{Y_i} \bigg]
\]</span>
</li>
</ul></section><section id="second-weighted-estimator" class="level2" data-number="5.6"><h2 data-number="5.6" class="anchored" data-anchor-id="second-weighted-estimator">
<span class="header-section-number">5.6</span> Second weighted estimator</h2>
<ul>
<li><p>The parameter functional for the NDE can also be expressed as a combination of regression and weighting: <span class="math display">\[
  \E\bigg[\color{RoyalBlue}{\frac{\I(A=0)}{\P(A=0\mid W)}}
  \times \color{Goldenrod}{\E(Y \mid A=1, M, W) -
  \E(Y \mid A=0, M, W)}\bigg]
\]</span></p></li>
<li><p>Thus, you can also construct a weighted estimator as <span class="math display">\[
  \frac{1}{n} \sum_{i=1}^n \bigg[\color{RoyalBlue}{
  \frac{\I(A_i=0)}{\hat{\P}(A_i=0\mid W_i)}} \times
  \color{Goldenrod}{\hat{\E}(Y \mid A=1, M_i, W_i) -
  \hat{\E}(Y \mid A=0, M_i, W_i)}\bigg]
\]</span></p></li>
</ul></section><section id="how-can-g-estimation-and-weighted-estimation-be-implemented-in-practice" class="level2" data-number="5.7"><h2 data-number="5.7" class="anchored" data-anchor-id="how-can-g-estimation-and-weighted-estimation-be-implemented-in-practice">
<span class="header-section-number">5.7</span> How can g-estimation and weighted estimation be implemented in practice?</h2>
<ul>
<li>There are two possible ways to do G-computation or weighted estimation:
<ul>
<li>Using parametric models for the above regressions</li>
<li>Using flexible data-adaptive regression (aka machine learning)</li>
</ul>
</li>
</ul></section><section id="pros-and-cons-of-g-computation-and-weighting-parametric-models" class="level2" data-number="5.8"><h2 data-number="5.8" class="anchored" data-anchor-id="pros-and-cons-of-g-computation-and-weighting-parametric-models">
<span class="header-section-number">5.8</span> Pros and cons of G-computation and weighting parametric models</h2>
<ul>
<li>Pros:
<ul>
<li>Easy to understand</li>
<li>Ease of implementation (standard regression software)</li>
<li>Can use the Delta method or the bootstrap for computation of standard errors</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Unless <span class="math inline">\(W\)</span> and <span class="math inline">\(M\)</span> contain very few categorical variables, it is very easy to misspecify the models</li>
<li>This can introduce sizable bias in the estimators</li>
<li>This modelling assumptions have become less necessary in the presence of data-adaptive regression tools (a.k.a., machine learning)</li>
</ul>
</li>
</ul></section><section id="an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect" class="level2" data-number="5.9"><h2 data-number="5.9" class="anchored" data-anchor-id="an-example-of-the-bias-of-a-g-computation-estimator-of-the-natural-direct-effect">
<span class="header-section-number">5.9</span> An example of the bias of a g-computation estimator of the natural direct effect</h2>
<ul>
<li>
<p>The following <code>R</code> chunk provides simulation code to exemplify the bias of a G-computation parametric estimator in a simple situation</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1"></a>mean_y <span class="ot">&lt;-</span> <span class="cf">function</span>(m, a, w) <span class="fu">abs</span>(w) <span class="sc">+</span> a <span class="sc">*</span> m</span>
<span id="cb3-2"><a href="#cb3-2"></a>mean_m <span class="ot">&lt;-</span> <span class="cf">function</span>(a, w) <span class="fu">plogis</span>(w<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> a)</span>
<span id="cb3-3"><a href="#cb3-3"></a>pscore <span class="ot">&lt;-</span> <span class="cf">function</span>(w) <span class="fu">plogis</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">abs</span>(w))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li><p>This yields a true NDE value of 0.5805</p></li>
<li>
<p>Let’s perform a simulation where we draw 1000 datasets from the above distribution, and compute a g-computation estimator based on</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1"></a>gcomp <span class="ot">&lt;-</span> <span class="cf">function</span>(y, m, a, w) {</span>
<span id="cb4-2"><a href="#cb4-2"></a>  lm_y <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> m <span class="sc">+</span> a <span class="sc">+</span> w)</span>
<span id="cb4-3"><a href="#cb4-3"></a>  pred_y1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_y, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">1</span>, <span class="at">m =</span> m, <span class="at">w =</span> w))</span>
<span id="cb4-4"><a href="#cb4-4"></a>  pred_y0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_y, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">m =</span> m, <span class="at">w =</span> w))</span>
<span id="cb4-5"><a href="#cb4-5"></a>  pseudo <span class="ot">&lt;-</span> pred_y1 <span class="sc">-</span> pred_y0</span>
<span id="cb4-6"><a href="#cb4-6"></a>  lm_pseudo <span class="ot">&lt;-</span> <span class="fu">lm</span>(pseudo <span class="sc">~</span> a <span class="sc">+</span> w)</span>
<span id="cb4-7"><a href="#cb4-7"></a>  pred_pseudo <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_pseudo, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">w =</span> w))</span>
<span id="cb4-8"><a href="#cb4-8"></a>  estimate <span class="ot">&lt;-</span> <span class="fu">mean</span>(pred_pseudo)</span>
<span id="cb4-9"><a href="#cb4-9"></a>  <span class="fu">return</span>(estimate)</span>
<span id="cb4-10"><a href="#cb4-10"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1"></a>estimate <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">seq_len</span>(<span class="dv">1000</span>), <span class="cf">function</span>(iter) {</span>
<span id="cb5-2"><a href="#cb5-2"></a>  n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  w <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb5-4"><a href="#cb5-4"></a>  a <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">pscore</span>(w))</span>
<span id="cb5-5"><a href="#cb5-5"></a>  m <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">mean_m</span>(a, w))</span>
<span id="cb5-6"><a href="#cb5-6"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="fu">mean_y</span>(m, a, w))</span>
<span id="cb5-7"><a href="#cb5-7"></a>  est <span class="ot">&lt;-</span> <span class="fu">gcomp</span>(y, m, a, w)</span>
<span id="cb5-8"><a href="#cb5-8"></a>  <span class="fu">return</span>(est)</span>
<span id="cb5-9"><a href="#cb5-9"></a>})</span>
<span id="cb5-10"><a href="#cb5-10"></a>estimate <span class="ot">&lt;-</span> <span class="fu">do.call</span>(c, estimate)</span>
<span id="cb5-11"><a href="#cb5-11"></a></span>
<span id="cb5-12"><a href="#cb5-12"></a><span class="fu">hist</span>(estimate)</span>
<span id="cb5-13"><a href="#cb5-13"></a><span class="fu">abline</span>(<span class="at">v =</span> trueval, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="estimation_natural_interv_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</li>
<li>
<p>The bias also affects the confidence intervals:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1"></a>cis <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb6-2"><a href="#cb6-2"></a>  estimate <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate),</span>
<span id="cb6-3"><a href="#cb6-3"></a>  estimate <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate)</span>
<span id="cb6-4"><a href="#cb6-4"></a>)</span>
<span id="cb6-5"><a href="#cb6-5"></a></span>
<span id="cb6-6"><a href="#cb6-6"></a>ord <span class="ot">&lt;-</span> <span class="fu">order</span>(<span class="fu">rowSums</span>(cis))</span>
<span id="cb6-7"><a href="#cb6-7"></a>lower <span class="ot">&lt;-</span> cis[ord, <span class="dv">1</span>]</span>
<span id="cb6-8"><a href="#cb6-8"></a>upper <span class="ot">&lt;-</span> cis[ord, <span class="dv">2</span>]</span>
<span id="cb6-9"><a href="#cb6-9"></a><span class="fu">curve</span>(trueval <span class="sc">+</span> <span class="dv">0</span> <span class="sc">*</span> x,</span>
<span id="cb6-10"><a href="#cb6-10"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1001</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb6-11"><a href="#cb6-11"></a>  <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">"Confidence interval"</span>, <span class="at">cex.axis =</span> <span class="fl">1.2</span>, <span class="at">cex.lab =</span> <span class="fl">1.2</span></span>
<span id="cb6-12"><a href="#cb6-12"></a>)</span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb6-14"><a href="#cb6-14"></a>  clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="fl">0.5</span>, <span class="dv">0</span>, <span class="fl">0.75</span>, <span class="fl">0.5</span>)</span>
<span id="cb6-15"><a href="#cb6-15"></a>  <span class="cf">if</span> (upper[i] <span class="sc">&lt;</span> trueval <span class="sc">||</span> lower[i] <span class="sc">&gt;</span> trueval) clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb6-16"><a href="#cb6-16"></a>  <span class="fu">points</span>(<span class="fu">rep</span>(i, <span class="dv">2</span>), <span class="fu">c</span>(lower[i], upper[i]), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> clr)</span>
<span id="cb6-17"><a href="#cb6-17"></a>}</span>
<span id="cb6-18"><a href="#cb6-18"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.10</span>, <span class="st">"n=1000 repetitions = 1000 "</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb6-19"><a href="#cb6-19"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.01</span>, <span class="fu">paste0</span>(</span>
<span id="cb6-20"><a href="#cb6-20"></a>  <span class="st">"Coverage probability = "</span>,</span>
<span id="cb6-21"><a href="#cb6-21"></a>  <span class="fu">mean</span>(lower <span class="sc">&lt;</span> trueval <span class="sc">&amp;</span> trueval <span class="sc">&lt;</span> upper), <span class="st">"%"</span></span>
<span id="cb6-22"><a href="#cb6-22"></a>), <span class="at">cex =</span> <span class="fl">1.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="estimation_natural_interv_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</li>
</ul></section><section id="pros-and-cons-of-g-computation-or-weighting-with-data-adaptive-regression" class="level2" data-number="5.10"><h2 data-number="5.10" class="anchored" data-anchor-id="pros-and-cons-of-g-computation-or-weighting-with-data-adaptive-regression">
<span class="header-section-number">5.10</span> Pros and cons of G-computation or weighting with data-adaptive regression</h2>
<ul>
<li>Pros:
<ul>
<li>Easy to understand.</li>
<li>Alleviate model-misspecification bias.</li>
</ul>
</li>
<li>Cons:
<ul>
<li>Might be harder to implement depending on the regression procedures used.</li>
<li>No general approaches for computation of standard errors and confidence intervals.</li>
<li>For example, the bootstrap is not guaranteed to work, and it is known to fail in some cases.</li>
</ul>
</li>
</ul></section><section id="solution-to-these-problems-robust-semiparametric-efficient-estimation" class="level2" data-number="5.11"><h2 data-number="5.11" class="anchored" data-anchor-id="solution-to-these-problems-robust-semiparametric-efficient-estimation">
<span class="header-section-number">5.11</span> Solution to these problems: robust semiparametric efficient estimation</h2>
<ul>
<li>Intuitively, it combines the three above estimators to obtain an estimator with improved robustness properties</li>
<li>It offers a way to use data-adaptive regression to
<ul>
<li>avoid model misspecification bias,</li>
<li>endow the estimators with additional robustness (e.g., multiple robustness), while</li>
<li>allowing the computation of correct standard errors and confidence intervals using Gaussian approximations</li>
</ul>
</li>
</ul>
<!--
 - This can be achieved by adding a bias correction factor the the
   G-computation as follows:
   \begin{equation*}
     \psi(\hat \P) + \frac{1}{n}\sum_{i=1}^n D(O_i)
   \end{equation*}
   for some function $D(O_i)$ of the data
 - The function $D(O)$ is called _the efficient influence function_ (EIF)
 - The EIF must be found on a case-by-case basis for each parameter $\psi(\P)$
 - For example, for estimating the standardized mean $\psi(\P)=\E[\E(Y\mid A=1,
   W)]$, we have
   \begin{equation*}
     D(O) = \frac{A}{\hat \P(A=1\mid W)}[Y - \hat\E(Y\mid A=1, W)] +
     \hat\E(Y\mid A=1, W) - \psi(\hat\P)
   \end{equation*}
 - The EIF is found by using a distributional analogue of a Taylor expansion
 - In this workshop we will omit the specific form of $D(O)$ for
   some of the parameters that we use
 - But the estimators we discuss and implement in the R packages will be based
   on these EIFs
 - And the specific form of the EIF may be found in papers in the references

 Note: the bias correction above may have an additional problem of
 returning parameter estimates outside of natural bounds. For example,
 probabilities greater than one. A solution to this (not discussed in
 this workshop but implemented in some of the R packages) is targeted
 minimum loss-based estimation.
--></section><section id="construction-of-a-semiparametric-efficient-estimator-for-the-nde-a.k.a.-the-one-step-estimator" class="level1 page-columns page-full" data-number="6"><h1 data-number="6">
<span class="header-section-number">6</span> Construction of a semiparametric efficient estimator for the NDE (a.k.a. the one-step estimator)</h1>
<!--
- For illustration, we will first present how to construct an estimator of the
  NDE that uses the EIF "by hand"
-->
<ul>
<li>Here we show the detail of how to construct an estimator for the NDE for illustration, but the construction of this estimator is a bit involved and may be complex in daily research practice</li>
<li>For practice, we will teach you how to use our packages <em>medoutcon</em> (and <em>medshift</em>, as detailed in the extra material) for automatic implementation of these estimators of the NDE and other parameters</li>
</ul>
<p>First, we need to introduce some notation to describe the EIF for the NDE</p>
<ul>
<li>Let <span class="math inline">\(Q(M, W)\)</span> denote <span class="math inline">\(\E(Y\mid A=1, M, W) - \E(Y\mid A=0, M, W)\)</span>
</li>
<li>We can now introduce the semiparametric efficient estimator:</li>
</ul>
<p><span class="math display">\[\begin{align*}
    \hat{\psi} &amp;= \frac{1}{n} \sum_{i=1}^n \color{RoyalBlue}{\bigg\{
      \frac{\I(A_i=1)}{\hat{\P}(A_i=1 \mid W_i)}
      \frac{\hat{\P}(M_i \mid A_i=0,W)_i}{\hat{\P}(M_i \mid A_i=1,W_i)} -
      \frac{\I(A=0)}{\hat{\P}(A_i=0 \mid W_i)}\bigg\}}
      \color{Goldenrod}{[Y_i - \hat{\E}(Y\mid A_i,M_i,W_i)]} \\
    &amp;+ \frac{1}{n} \sum_{i=1}^n \color{RoyalBlue}{\frac{\I(A=0)}{\P(A=0 \mid
      W)}} \color{Goldenrod}{\big\{ \hat{Q}(M_i,W_i) -
      \hat{\E}[\hat{Q}(M_i,W_i) \mid W_i, A_i = 0] \big\}} \\
    &amp;+ \frac{1}{n} \sum_{i=1}^n \color{Goldenrod}{
      \hat{\E}[\hat{Q}(M_i,W_i) \mid W_i,A_i=0]}
\end{align*}\]</span></p>
<ul>
<li>In this estimator, you can recognize elements from the G-computation estimator and the weighted estimators:
<ul>
<li>The third line is the G-computation estimator</li>
<li>The second line is a centered version of the second weighted estimator</li>
<li>The first line is a centered version of the first weighted estimator</li>
</ul>
</li>
<li>Estimating <span class="math inline">\(\P(M\mid A, W)\)</span> is a very challenging problem when <span class="math inline">\(M\)</span> is high-dimensional. But, since we have the ratio of these conditional densities, we can re-paramterize using Bayes’ rule to get something that is easier to compute: <span class="math display">\[\begin{equation*}
  \frac{\P(M \mid A=0, W)}{\P(M \mid A=1,W)} = \frac{\P(A = 0 \mid M, W)
    \P(A=1 \mid W)}{\P(A = 1 \mid M, W) \P(A=0 \mid W)} \ .
\end{equation*}\]</span>
</li>
</ul>
<p>Thus we can change the expression of the estimator a bit as follows. First, some more notation that will be useful later:</p>
<ul>
<li>Let <span class="math inline">\(g(a\mid w)\)</span> denote <span class="math inline">\(\P(A=a\mid W=w)\)</span>
</li>
<li>Let <span class="math inline">\(e(a\mid m, w)\)</span> denote <span class="math inline">\(\P(A=a\mid M=m, W=w)\)</span>
</li>
<li>Let <span class="math inline">\(b(a, m, w)\)</span> denote <span class="math inline">\(\E(Y\mid A=a, M=m, W=w)\)</span>
</li>
<li>The quantity being averaged can be re-expressed as follows</li>
</ul>
<p><span class="math display">\[\begin{align*}
    &amp; \color{RoyalBlue}{\bigg\{ \frac{\I(A=1)}{g(0\mid W)}
      \frac{e(0\mid M,W)}{e(1\mid M,W)} - \frac{\I(A=0)}{g(0\mid W)}\bigg\}}
      \times \color{Goldenrod}{[Y - b(A,M,W)]} \\
    &amp;+ \color{RoyalBlue}{\frac{\I(A=0)}{g(0\mid W)}}
      \color{Goldenrod}{\big\{Q(M,W) - \E[Q(M,W) \mid W, A=0] \big\}} \\
    &amp;+ \color{Goldenrod}{\E[Q(M,W) \mid W, A=0]}
\end{align*}\]</span></p>
<section id="how-to-compute-the-one-step-estimator-akin-to-augmented-ipw" class="level2 page-columns page-full" data-number="6.1"><h2 data-number="6.1" class="anchored" data-anchor-id="how-to-compute-the-one-step-estimator-akin-to-augmented-ipw">
<span class="header-section-number">6.1</span> How to compute the one-step estimator (akin to Augmented IPW)</h2>
<p>First we will generate some data:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1"></a>mean_y <span class="ot">&lt;-</span> <span class="cf">function</span>(m, a, w) <span class="fu">abs</span>(w) <span class="sc">+</span> a <span class="sc">*</span> m</span>
<span id="cb7-2"><a href="#cb7-2"></a>mean_m <span class="ot">&lt;-</span> <span class="cf">function</span>(a, w)<span class="fu">plogis</span>(w<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> a)</span>
<span id="cb7-3"><a href="#cb7-3"></a>pscore <span class="ot">&lt;-</span> <span class="cf">function</span>(w) <span class="fu">plogis</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">abs</span>(w))</span>
<span id="cb7-4"><a href="#cb7-4"></a></span>
<span id="cb7-5"><a href="#cb7-5"></a>w_big <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-6"><a href="#cb7-6"></a>trueval <span class="ot">&lt;-</span> <span class="fu">mean</span>((<span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)</span>
<span id="cb7-7"><a href="#cb7-7"></a>                <span class="sc">+</span> (<span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span></span>
<span id="cb7-8"><a href="#cb7-8"></a>                  (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)))</span>
<span id="cb7-9"><a href="#cb7-9"></a></span>
<span id="cb7-10"><a href="#cb7-10"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb7-11"><a href="#cb7-11"></a>w <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb7-12"><a href="#cb7-12"></a>a <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">pscore</span>(w))</span>
<span id="cb7-13"><a href="#cb7-13"></a>m <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">mean_m</span>(a, w))</span>
<span id="cb7-14"><a href="#cb7-14"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="fu">mean_y</span>(m, a, w))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Recall that the semiparametric efficient estimator can be computed in the following steps:</p>
<ol type="1">
<li>
<p>Fit models for <span class="math inline">\(g(a\mid w)\)</span>, <span class="math inline">\(e(a\mid m, w)\)</span>, and <span class="math inline">\(b(a, m, w)\)</span></p>
<ul>
<li>In this example we will use Generalized Additive Models for tractability</li>
<li>In applied settings we recommend using an ensemble of data-adaptive regression algorithms, such as the Super Learner <span class="citation" data-cites="vdl2007super">(<a href="#ref-vdl2007super" role="doc-biblioref">van der Laan, Polley, and Hubbard 2007</a>)</span>
</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="do">## fit model for E(Y | A, W)</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>b_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> m<span class="sc">:</span>a <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="do">## fit model for P(A = 1 | M, W)</span></span>
<span id="cb8-5"><a href="#cb8-5"></a>e_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> m <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> m), <span class="at">family =</span> binomial)</span>
<span id="cb8-6"><a href="#cb8-6"></a><span class="do">## fit model for P(A = 1 | W)</span></span>
<span id="cb8-7"><a href="#cb8-7"></a>g_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> w, <span class="at">family =</span> binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li>
<p>Compute predictions <span class="math inline">\(g(1\mid w)\)</span>, <span class="math inline">\(g(0\mid w)\)</span>, <span class="math inline">\(e(1\mid m, w)\)</span>, <span class="math inline">\(e(0\mid m, w)\)</span>,<span class="math inline">\(b(1, m, w)\)</span>, <span class="math inline">\(b(0, m, w)\)</span>, and <span class="math inline">\(b(a, m, w)\)</span></p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1"></a><span class="do">## Compute P(A = 1 | W)</span></span>
<span id="cb9-2"><a href="#cb9-2"></a>g1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(g_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="do">## Compute P(A = 0 | W)</span></span>
<span id="cb9-4"><a href="#cb9-4"></a>g0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> g1_pred</span>
<span id="cb9-5"><a href="#cb9-5"></a><span class="do">## Compute P(A = 1 | M, W)</span></span>
<span id="cb9-6"><a href="#cb9-6"></a>e1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(e_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb9-7"><a href="#cb9-7"></a><span class="do">## Compute P(A = 0 | M, W)</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>e0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> e1_pred</span>
<span id="cb9-9"><a href="#cb9-9"></a><span class="do">## Compute E(Y | A = 1, M, W)</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>b1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">1</span>, m, w))</span>
<span id="cb9-11"><a href="#cb9-11"></a><span class="do">## Compute E(Y | A = 0, M, W)</span></span>
<span id="cb9-12"><a href="#cb9-12"></a>b0_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, m, w))</span>
<span id="cb9-13"><a href="#cb9-13"></a><span class="do">## Compute E(Y | A, M, W)</span></span>
<span id="cb9-14"><a href="#cb9-14"></a>b_pred  <span class="ot">&lt;-</span> <span class="fu">predict</span>(b_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li>
<p>Compute <span class="math inline">\(Q(M, W)\)</span>, fit a model for <span class="math inline">\(\E[Q(M,W) \mid W,A]\)</span>, and predict at <span class="math inline">\(A=0\)</span></p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a><span class="do">## Compute Q(M, W)</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>pseudo <span class="ot">&lt;-</span> b1_pred <span class="sc">-</span> b0_pred</span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="do">## Fit model for E[Q(M, W) | A, W]</span></span>
<span id="cb10-4"><a href="#cb10-4"></a>q_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(pseudo <span class="sc">~</span> a <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="do">## Compute E[Q(M, W) | A = 0, W]</span></span>
<span id="cb10-6"><a href="#cb10-6"></a>q_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(q_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">w =</span> w))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li>
<p>Estimate the weights</p>
<p><span class="math display">\[\begin{equation*}
\color{RoyalBlue}{\bigg\{
  \frac{\I(A=1)}{g(0\mid W)} \frac{e(0 \mid M,W)}{e(1 \mid M,W)} -
  \frac{\I(A=0)}{g(0\mid W)} \bigg\}}
\end{equation*}\]</span> using the above predictions:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1"></a>ip_weights <span class="ot">&lt;-</span> a <span class="sc">/</span> g0_pred <span class="sc">*</span> e0_pred <span class="sc">/</span> e1_pred <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li>
<p>Compute the uncentered EIF:</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1"></a>eif <span class="ot">&lt;-</span> ip_weights <span class="sc">*</span> (y <span class="sc">-</span> b_pred) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred <span class="sc">*</span> (pseudo <span class="sc">-</span> q_pred) <span class="sc">+</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>  q_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</li>
<li>
<p>The one step estimator is the mean of the uncentered EIF</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1"></a><span class="do">## One-step estimator</span></span>
<span id="cb13-2"><a href="#cb13-2"></a><span class="fu">mean</span>(eif)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.4608033</code></pre>
</div>
</div>
</li>
</ol><div class="no-row-height column-margin column-container"><div id="ref-vdl2007super" class="csl-entry" role="listitem">
van der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. <span>“<span>Super Learner</span>.”</span> <em>Statistical Applications in Genetics and Molecular Biology</em> 6 (1).
</div></div></section><section id="performance-of-the-one-step-estimator-in-a-small-simulation-study" class="level2" data-number="6.2"><h2 data-number="6.2" class="anchored" data-anchor-id="performance-of-the-one-step-estimator-in-a-small-simulation-study">
<span class="header-section-number">6.2</span> Performance of the one-step estimator in a small simulation study</h2>
<p>First, we create a wrapper around the estimator</p>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1"></a>one_step <span class="ot">&lt;-</span> <span class="cf">function</span>(y, m, a, w) {</span>
<span id="cb15-2"><a href="#cb15-2"></a>  b_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> m<span class="sc">:</span>a <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb15-3"><a href="#cb15-3"></a>  e_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> m <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> m), <span class="at">family =</span> binomial)</span>
<span id="cb15-4"><a href="#cb15-4"></a>  g_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> w, <span class="at">family =</span> binomial)</span>
<span id="cb15-5"><a href="#cb15-5"></a>  g1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(g_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb15-6"><a href="#cb15-6"></a>  g0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> g1_pred</span>
<span id="cb15-7"><a href="#cb15-7"></a>  e1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(e_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb15-8"><a href="#cb15-8"></a>  e0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> e1_pred</span>
<span id="cb15-9"><a href="#cb15-9"></a>  b1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb15-10"><a href="#cb15-10"></a>    b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">1</span>, m, w), <span class="at">type =</span> <span class="st">'response'</span></span>
<span id="cb15-11"><a href="#cb15-11"></a>  )</span>
<span id="cb15-12"><a href="#cb15-12"></a>  b0_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb15-13"><a href="#cb15-13"></a>    b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, m, w), <span class="at">type =</span> <span class="st">'response'</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>  )</span>
<span id="cb15-15"><a href="#cb15-15"></a>  b_pred  <span class="ot">&lt;-</span> <span class="fu">predict</span>(b_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb15-16"><a href="#cb15-16"></a>  pseudo <span class="ot">&lt;-</span> b1_pred <span class="sc">-</span> b0_pred</span>
<span id="cb15-17"><a href="#cb15-17"></a>  q_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(pseudo <span class="sc">~</span> a <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb15-18"><a href="#cb15-18"></a>  q_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(q_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">w =</span> w))</span>
<span id="cb15-19"><a href="#cb15-19"></a>  ip_weights <span class="ot">&lt;-</span> a <span class="sc">/</span> g0_pred <span class="sc">*</span> e0_pred <span class="sc">/</span> e1_pred <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred</span>
<span id="cb15-20"><a href="#cb15-20"></a>  eif <span class="ot">&lt;-</span> ip_weights <span class="sc">*</span> (y <span class="sc">-</span> b_pred) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred <span class="sc">*</span></span>
<span id="cb15-21"><a href="#cb15-21"></a>    (pseudo <span class="sc">-</span> q_pred) <span class="sc">+</span> q_pred</span>
<span id="cb15-22"><a href="#cb15-22"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(eif))</span>
<span id="cb15-23"><a href="#cb15-23"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Let us first examine the bias</p>
<ul>
<li>The true value is:</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1"></a>w_big <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb16-2"><a href="#cb16-2"></a>trueval <span class="ot">&lt;-</span> <span class="fu">mean</span>((<span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)</span>
<span id="cb16-3"><a href="#cb16-3"></a>  <span class="sc">+</span> (<span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)))</span>
<span id="cb16-4"><a href="#cb16-4"></a><span class="fu">print</span>(trueval)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5805508</code></pre>
</div>
</div>
<ul>
<li>Bias simulation</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1"></a>estimate <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">seq_len</span>(<span class="dv">1000</span>), <span class="cf">function</span>(iter) {</span>
<span id="cb18-2"><a href="#cb18-2"></a>  n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb18-3"><a href="#cb18-3"></a>  w <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb18-4"><a href="#cb18-4"></a>  a <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">pscore</span>(w))</span>
<span id="cb18-5"><a href="#cb18-5"></a>  m <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">mean_m</span>(a, w))</span>
<span id="cb18-6"><a href="#cb18-6"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="fu">mean_y</span>(m, a, w))</span>
<span id="cb18-7"><a href="#cb18-7"></a>  estimate <span class="ot">&lt;-</span> <span class="fu">one_step</span>(y, m, a, w)</span>
<span id="cb18-8"><a href="#cb18-8"></a>  <span class="fu">return</span>(estimate)</span>
<span id="cb18-9"><a href="#cb18-9"></a>})</span>
<span id="cb18-10"><a href="#cb18-10"></a>estimate <span class="ot">&lt;-</span> <span class="fu">do.call</span>(c, estimate)</span>
<span id="cb18-11"><a href="#cb18-11"></a></span>
<span id="cb18-12"><a href="#cb18-12"></a><span class="fu">hist</span>(estimate)</span>
<span id="cb18-13"><a href="#cb18-13"></a><span class="fu">abline</span>(<span class="at">v =</span> trueval, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="estimation_natural_interv_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>And now the confidence intervals:</li>
</ul>
<div class="cell">
<details class="code-fold"><summary>Code</summary><div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource r number-lines code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1"></a>cis <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb19-2"><a href="#cb19-2"></a>  estimate <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate),</span>
<span id="cb19-3"><a href="#cb19-3"></a>  estimate <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate)</span>
<span id="cb19-4"><a href="#cb19-4"></a>)</span>
<span id="cb19-5"><a href="#cb19-5"></a></span>
<span id="cb19-6"><a href="#cb19-6"></a>ord <span class="ot">&lt;-</span> <span class="fu">order</span>(<span class="fu">rowSums</span>(cis))</span>
<span id="cb19-7"><a href="#cb19-7"></a>lower <span class="ot">&lt;-</span> cis[ord, <span class="dv">1</span>]</span>
<span id="cb19-8"><a href="#cb19-8"></a>upper <span class="ot">&lt;-</span> cis[ord, <span class="dv">2</span>]</span>
<span id="cb19-9"><a href="#cb19-9"></a><span class="fu">curve</span>(trueval <span class="sc">+</span> <span class="dv">0</span> <span class="sc">*</span> x,</span>
<span id="cb19-10"><a href="#cb19-10"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1001</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb19-11"><a href="#cb19-11"></a>  <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">"Confidence interval"</span>, <span class="at">cex.axis =</span> <span class="fl">1.2</span>, <span class="at">cex.lab =</span> <span class="fl">1.2</span></span>
<span id="cb19-12"><a href="#cb19-12"></a>)</span>
<span id="cb19-13"><a href="#cb19-13"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb19-14"><a href="#cb19-14"></a>  clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="fl">0.5</span>, <span class="dv">0</span>, <span class="fl">0.75</span>, <span class="fl">0.5</span>)</span>
<span id="cb19-15"><a href="#cb19-15"></a>  <span class="cf">if</span> (upper[i] <span class="sc">&lt;</span> trueval <span class="sc">||</span> lower[i] <span class="sc">&gt;</span> trueval) clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb19-16"><a href="#cb19-16"></a>  <span class="fu">points</span>(<span class="fu">rep</span>(i, <span class="dv">2</span>), <span class="fu">c</span>(lower[i], upper[i]), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> clr)</span>
<span id="cb19-17"><a href="#cb19-17"></a>}</span>
<span id="cb19-18"><a href="#cb19-18"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.10</span>, <span class="st">"n=1000 repetitions = 1000 "</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb19-19"><a href="#cb19-19"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.01</span>, <span class="fu">paste0</span>(</span>
<span id="cb19-20"><a href="#cb19-20"></a>  <span class="st">"Coverage probability = "</span>,</span>
<span id="cb19-21"><a href="#cb19-21"></a>  <span class="fu">mean</span>(lower <span class="sc">&lt;</span> trueval <span class="sc">&amp;</span> trueval <span class="sc">&lt;</span> upper), <span class="st">"%"</span></span>
<span id="cb19-22"><a href="#cb19-22"></a>), <span class="at">cex =</span> <span class="fl">1.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details><div class="cell-output-display">
<div>
<figure class="figure"><p><img src="estimation_natural_interv_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
</section><section id="a-note-about-targeted-minimum-loss-based-estimation-tmle" class="level2" data-number="6.3"><h2 data-number="6.3" class="anchored" data-anchor-id="a-note-about-targeted-minimum-loss-based-estimation-tmle">
<span class="header-section-number">6.3</span> A note about targeted minimum loss-based estimation (TMLE)</h2>
<ul>
<li>The above estimator is great because it allows us to use data-adaptive regression to avoid bias, while allowing the computation of correct standard errors</li>
<li>This estimator has a problem, though:
<ul>
<li>It can yield answers outside of the bounds of the parameter space</li>
<li>E.g., if <span class="math inline">\(Y\)</span> is binary, it could yield direct and indirect effects outside of <span class="math inline">\([-1,1]\)</span>
</li>
<li>To solve this, you can compute a TMLE instead (implemented in the R packages, coming up)</li>
</ul>
</li>
</ul></section><section id="a-note-about-cross-fitting" class="level2" data-number="6.4"><h2 data-number="6.4" class="anchored" data-anchor-id="a-note-about-cross-fitting">
<span class="header-section-number">6.4</span> A note about cross-fitting</h2>
<ul>
<li>When using data-adaptive regression estimators, it is recommended to use cross-fitted estimators</li>
<li>Cross-fitting is similar to cross-validation:
<ul>
<li>Randomly split the sample into K (e.g., K=10) subsets of equal size</li>
<li>For each of the 9/10ths of the sample, fit the regression models</li>
<li>Use the out-of-sample fit to predict in the remaining 1/10th of the sample</li>
</ul>
</li>
<li>Cross-fitting further reduces the bias of the estimators</li>
<li>Cross-fitting aids in guaranteeing the correctness of the standard errors and confidence intervals</li>
<li>Cross-fitting is implemented by default in the R packages that you will see next</li>
</ul>


<!-- -->


</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/codex\.nimahejazi\.org\/causal_mediation_workshops\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./estimation_prelims.html" class="pagination-link" aria-label="Estimation preliminaries: review of doubly robust estimators for the average treatment effect">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Estimation preliminaries: review of doubly robust estimators for the average treatment effect</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./estimation_walkthrough.html" class="pagination-link" aria-label="`R` packages for estimation of the causal (in)direct effects">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><code>R</code> packages for estimation of the causal (in)direct effects</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb20" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb20-1"><a href="#cb20-1"></a><span class="fu"># Construction of G-computation and weighted estimators for the NDE: The case of the natural direct effect</span></span>
<span id="cb20-2"><a href="#cb20-2"></a></span>
<span id="cb20-5"><a href="#cb20-5"></a><span class="in">```{r}</span></span>
<span id="cb20-6"><a href="#cb20-6"></a><span class="co">#| label: load-renv</span></span>
<span id="cb20-7"><a href="#cb20-7"></a><span class="co">#| echo: false</span></span>
<span id="cb20-8"><a href="#cb20-8"></a><span class="co">#| message: false</span></span>
<span id="cb20-9"><a href="#cb20-9"></a>renv<span class="sc">::</span><span class="fu">load</span>(here<span class="sc">::</span><span class="fu">here</span>())</span>
<span id="cb20-10"><a href="#cb20-10"></a><span class="fu">library</span>(here)</span>
<span id="cb20-11"><a href="#cb20-11"></a><span class="in">```</span></span>
<span id="cb20-12"><a href="#cb20-12"></a></span>
<span id="cb20-13"><a href="#cb20-13"></a><span class="fu">## Recap of definition and identification of the natural direct effect</span></span>
<span id="cb20-14"><a href="#cb20-14"></a></span>
<span id="cb20-15"><a href="#cb20-15"></a>Recall:</span>
<span id="cb20-16"><a href="#cb20-16"></a></span>
<span id="cb20-19"><a href="#cb20-19"></a><span class="in">```{tikz}</span></span>
<span id="cb20-20"><a href="#cb20-20"></a><span class="in">#| fig-cap: Directed acyclic graph under *no intermediate confounders* of the mediator-outcome relation affected by treatment</span></span>
<span id="cb20-21"><a href="#cb20-21"></a><span class="in">\dimendef\prevdepth=0</span></span>
<span id="cb20-22"><a href="#cb20-22"></a><span class="in">\pgfdeclarelayer{background}</span></span>
<span id="cb20-23"><a href="#cb20-23"></a><span class="in">\pgfsetlayers{background,main}</span></span>
<span id="cb20-24"><a href="#cb20-24"></a><span class="in">\usetikzlibrary{arrows,positioning}</span></span>
<span id="cb20-25"><a href="#cb20-25"></a><span class="in">\tikzset{</span></span>
<span id="cb20-26"><a href="#cb20-26"></a><span class="in">&gt;=stealth',</span></span>
<span id="cb20-27"><a href="#cb20-27"></a><span class="in">punkt/.style={</span></span>
<span id="cb20-28"><a href="#cb20-28"></a><span class="in">rectangle,</span></span>
<span id="cb20-29"><a href="#cb20-29"></a><span class="in">rounded corners,</span></span>
<span id="cb20-30"><a href="#cb20-30"></a><span class="in">draw=black, very thick,</span></span>
<span id="cb20-31"><a href="#cb20-31"></a><span class="in">text width=6.5em,</span></span>
<span id="cb20-32"><a href="#cb20-32"></a><span class="in">minimum height=2em,</span></span>
<span id="cb20-33"><a href="#cb20-33"></a><span class="in">text centered},</span></span>
<span id="cb20-34"><a href="#cb20-34"></a><span class="in">pil/.style={</span></span>
<span id="cb20-35"><a href="#cb20-35"></a><span class="in">-&gt;,</span></span>
<span id="cb20-36"><a href="#cb20-36"></a><span class="in">thick,</span></span>
<span id="cb20-37"><a href="#cb20-37"></a><span class="in">shorten &lt;=2pt,</span></span>
<span id="cb20-38"><a href="#cb20-38"></a><span class="in">shorten &gt;=2pt,}</span></span>
<span id="cb20-39"><a href="#cb20-39"></a><span class="in">}</span></span>
<span id="cb20-40"><a href="#cb20-40"></a><span class="in">\newcommand{\Vertex}[2]</span></span>
<span id="cb20-41"><a href="#cb20-41"></a><span class="in">{\node[minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};</span></span>
<span id="cb20-42"><a href="#cb20-42"></a><span class="in">}</span></span>
<span id="cb20-43"><a href="#cb20-43"></a><span class="in">\newcommand{\VertexR}[2]</span></span>
<span id="cb20-44"><a href="#cb20-44"></a><span class="in">{\node[rectangle, draw, minimum width=0.6cm,inner sep=0.05cm] (#2) at (#1) {$#2$};</span></span>
<span id="cb20-45"><a href="#cb20-45"></a><span class="in">}</span></span>
<span id="cb20-46"><a href="#cb20-46"></a><span class="in">\newcommand{\ArrowR}[3]</span></span>
<span id="cb20-47"><a href="#cb20-47"></a><span class="in">{ \begin{pgfonlayer}{background}</span></span>
<span id="cb20-48"><a href="#cb20-48"></a><span class="in">\draw[-&gt;,#3] (#1) to[bend right=30] (#2);</span></span>
<span id="cb20-49"><a href="#cb20-49"></a><span class="in">\end{pgfonlayer}</span></span>
<span id="cb20-50"><a href="#cb20-50"></a><span class="in">}</span></span>
<span id="cb20-51"><a href="#cb20-51"></a><span class="in">\newcommand{\ArrowL}[3]</span></span>
<span id="cb20-52"><a href="#cb20-52"></a><span class="in">{ \begin{pgfonlayer}{background}</span></span>
<span id="cb20-53"><a href="#cb20-53"></a><span class="in">\draw[-&gt;,#3] (#1) to[bend left=45] (#2);</span></span>
<span id="cb20-54"><a href="#cb20-54"></a><span class="in">\end{pgfonlayer}</span></span>
<span id="cb20-55"><a href="#cb20-55"></a><span class="in">}</span></span>
<span id="cb20-56"><a href="#cb20-56"></a><span class="in">\newcommand{\EdgeL}[3]</span></span>
<span id="cb20-57"><a href="#cb20-57"></a><span class="in">{ \begin{pgfonlayer}{background}</span></span>
<span id="cb20-58"><a href="#cb20-58"></a><span class="in">\draw[dashed,#3] (#1) to[bend right=-45] (#2);</span></span>
<span id="cb20-59"><a href="#cb20-59"></a><span class="in">\end{pgfonlayer}</span></span>
<span id="cb20-60"><a href="#cb20-60"></a><span class="in">}</span></span>
<span id="cb20-61"><a href="#cb20-61"></a><span class="in">\newcommand{\Arrow}[3]</span></span>
<span id="cb20-62"><a href="#cb20-62"></a><span class="in">{ \begin{pgfonlayer}{background}</span></span>
<span id="cb20-63"><a href="#cb20-63"></a><span class="in">\draw[-&gt;,#3] (#1) -- +(#2);</span></span>
<span id="cb20-64"><a href="#cb20-64"></a><span class="in">\end{pgfonlayer}</span></span>
<span id="cb20-65"><a href="#cb20-65"></a><span class="in">}</span></span>
<span id="cb20-66"><a href="#cb20-66"></a><span class="in">\begin{tikzpicture}</span></span>
<span id="cb20-67"><a href="#cb20-67"></a><span class="in">  \Vertex{-4, 0}{W}</span></span>
<span id="cb20-68"><a href="#cb20-68"></a><span class="in">  \Vertex{0, 0}{M}</span></span>
<span id="cb20-69"><a href="#cb20-69"></a><span class="in">  \Vertex{-2, 0}{A}</span></span>
<span id="cb20-70"><a href="#cb20-70"></a><span class="in">  \Vertex{2, 0}{Y}</span></span>
<span id="cb20-71"><a href="#cb20-71"></a><span class="in">  \Arrow{W}{A}{black}</span></span>
<span id="cb20-72"><a href="#cb20-72"></a><span class="in">  \Arrow{A}{M}{black}</span></span>
<span id="cb20-73"><a href="#cb20-73"></a><span class="in">  \Arrow{M}{Y}{black}</span></span>
<span id="cb20-74"><a href="#cb20-74"></a><span class="in">  \ArrowL{W}{Y}{black}</span></span>
<span id="cb20-75"><a href="#cb20-75"></a><span class="in">  \ArrowL{A}{Y}{black}</span></span>
<span id="cb20-76"><a href="#cb20-76"></a><span class="in">  \ArrowL{W}{M}{black}</span></span>
<span id="cb20-77"><a href="#cb20-77"></a><span class="in">\end{tikzpicture}</span></span>
<span id="cb20-78"><a href="#cb20-78"></a><span class="in">```</span></span>
<span id="cb20-79"><a href="#cb20-79"></a></span>
<span id="cb20-80"><a href="#cb20-80"></a><span class="ss">- </span>Assuming a binary $A$, we define the natural direct effect as:</span>
<span id="cb20-81"><a href="#cb20-81"></a>  $\text{NDE} = \E(Y_{1,M_{0}} - Y_{0,M_{0}})$.</span>
<span id="cb20-82"><a href="#cb20-82"></a><span class="ss">- </span>and the natural indirect effect as:</span>
<span id="cb20-83"><a href="#cb20-83"></a>  $\text{NIE} = \E(Y_{1,M_{1}} - Y_{1,M_{0}})$.</span>
<span id="cb20-84"><a href="#cb20-84"></a><span class="ss">- </span>The observed data is $O = (W, A, M, Y)$</span>
<span id="cb20-85"><a href="#cb20-85"></a></span>
<span id="cb20-86"><a href="#cb20-86"></a>This SCM is represented in the above DAG and the following causal models:</span>
<span id="cb20-87"><a href="#cb20-87"></a>\begin{align*}</span>
<span id="cb20-88"><a href="#cb20-88"></a>  W &amp; = f_W(U_W) <span class="sc">\\</span></span>
<span id="cb20-89"><a href="#cb20-89"></a>  A &amp; = f_A(W, U_A) <span class="sc">\\</span></span>
<span id="cb20-90"><a href="#cb20-90"></a>  M &amp; = f_M(W, A, U_M) <span class="sc">\\</span></span>
<span id="cb20-91"><a href="#cb20-91"></a>  Y &amp; = f_Y(W, A, M, U_Y),</span>
<span id="cb20-92"><a href="#cb20-92"></a>\end{align*}</span>
<span id="cb20-93"><a href="#cb20-93"></a>where $(U_W, U_A,U_M, U_Y)$ are exogenous random errors.</span>
<span id="cb20-94"><a href="#cb20-94"></a></span>
<span id="cb20-95"><a href="#cb20-95"></a>Recall that we need to assume the following to identify the above causal</span>
<span id="cb20-96"><a href="#cb20-96"></a>effects from our observed data:</span>
<span id="cb20-97"><a href="#cb20-97"></a></span>
<span id="cb20-98"><a href="#cb20-98"></a><span class="ss">- </span>$A \indep Y_{a,m} \mid W$</span>
<span id="cb20-99"><a href="#cb20-99"></a><span class="ss">- </span>$M \indep Y_{a,m} \mid W, A$</span>
<span id="cb20-100"><a href="#cb20-100"></a><span class="ss">- </span>$A \indep M_a \mid W$</span>
<span id="cb20-101"><a href="#cb20-101"></a><span class="ss">- </span>$M_0 \indep Y_{1,m} \mid W$</span>
<span id="cb20-102"><a href="#cb20-102"></a><span class="ss">- </span>and positivity assumptions</span>
<span id="cb20-103"><a href="#cb20-103"></a></span>
<span id="cb20-104"><a href="#cb20-104"></a>Then, the NDE is identified as</span>
<span id="cb20-105"><a href="#cb20-105"></a>  $$</span>
<span id="cb20-106"><a href="#cb20-106"></a>    \psi(\P) = \E<span class="co">[</span><span class="ot">\E\{\E(Y \mid A=1, M, W) - \E(Y \mid A=0, M, W) \mid A=0,W\}</span><span class="co">]</span></span>
<span id="cb20-107"><a href="#cb20-107"></a>  $$</span>
<span id="cb20-108"><a href="#cb20-108"></a></span>
<span id="cb20-109"><a href="#cb20-109"></a><span class="fu">## From causal to statistical quantities</span></span>
<span id="cb20-110"><a href="#cb20-110"></a><span class="ss">- </span>We have arrived at identification formulas that express quantities that we</span>
<span id="cb20-111"><a href="#cb20-111"></a>  care about in terms of observable quantities</span>
<span id="cb20-112"><a href="#cb20-112"></a><span class="ss">- </span>That is, these formulas express what would have happened in hypothetical</span>
<span id="cb20-113"><a href="#cb20-113"></a>  worlds in terms of quantities observable in this world.</span>
<span id="cb20-114"><a href="#cb20-114"></a><span class="ss">- </span>This required **causal assumptions**</span>
<span id="cb20-115"><a href="#cb20-115"></a><span class="ss">  - </span>Many of these assumptions are empirically unverifiable</span>
<span id="cb20-116"><a href="#cb20-116"></a><span class="ss">  - </span>We saw an example where we could relax the cross-world assumption, at the</span>
<span id="cb20-117"><a href="#cb20-117"></a>    cost of changing the parameter interpretation (when we introduced randomized</span>
<span id="cb20-118"><a href="#cb20-118"></a>    interventional direct and indirect effects).</span>
<span id="cb20-119"><a href="#cb20-119"></a><span class="ss">  - </span>We also include an extra section at the end about **stochastic** randomized</span>
<span id="cb20-120"><a href="#cb20-120"></a>    interventional direct and indirect effects, which allow us to relax the</span>
<span id="cb20-121"><a href="#cb20-121"></a>    positivity assumption, also at the cost of changing the parameter</span>
<span id="cb20-122"><a href="#cb20-122"></a>    interpretation.</span>
<span id="cb20-123"><a href="#cb20-123"></a><span class="ss">- </span>We are now ready to tackle the estimation problem, i.e., how do we best learn</span>
<span id="cb20-124"><a href="#cb20-124"></a>  the value of quantities that are observable?</span>
<span id="cb20-125"><a href="#cb20-125"></a><span class="ss">- </span>The resulting estimation problem can be tackled using **statistical</span>
<span id="cb20-126"><a href="#cb20-126"></a>  assumptions** of various degrees of strength</span>
<span id="cb20-127"><a href="#cb20-127"></a><span class="ss">  - </span>Most of these assumptions are verifiable (e.g., a linear model)</span>
<span id="cb20-128"><a href="#cb20-128"></a><span class="ss">  - </span>Thus, most are unnecessary (except for convenience)</span>
<span id="cb20-129"><a href="#cb20-129"></a><span class="ss">  - </span>We have worked hard to try to satisfy the required causal assumptions</span>
<span id="cb20-130"><a href="#cb20-130"></a><span class="ss">  - </span>This is not the time to introduce unnecessary statistical assumptions</span>
<span id="cb20-131"><a href="#cb20-131"></a><span class="ss">  - </span>The estimation approach we will minimizes reliance on these statistical</span>
<span id="cb20-132"><a href="#cb20-132"></a>    assumptions.</span>
<span id="cb20-133"><a href="#cb20-133"></a></span>
<span id="cb20-134"><a href="#cb20-134"></a><span class="fu">## Computing identification formulas if you know the true distribution</span></span>
<span id="cb20-135"><a href="#cb20-135"></a></span>
<span id="cb20-136"><a href="#cb20-136"></a><span class="ss">- </span>The mediation parameters that we consider can be seen as a function of the</span>
<span id="cb20-137"><a href="#cb20-137"></a>  joint probability distribution of observed data $O=(W,A,Z,M,Y)$</span>
<span id="cb20-138"><a href="#cb20-138"></a><span class="ss">- </span>For example, under identifiability assumptions the natural direct effect is</span>
<span id="cb20-139"><a href="#cb20-139"></a>  equal to</span>
<span id="cb20-140"><a href="#cb20-140"></a>  $$</span>
<span id="cb20-141"><a href="#cb20-141"></a>    \psi(\P) = \E[\color{Goldenrod}{\E<span class="sc">\{</span>\color{ForestGreen}</span>
<span id="cb20-142"><a href="#cb20-142"></a>      {\E(Y \mid A=1, M, W) - \E(Y \mid A=0, M, W)} \mid A=0, W <span class="sc">\}</span>}]</span>
<span id="cb20-143"><a href="#cb20-143"></a>  $$</span>
<span id="cb20-144"><a href="#cb20-144"></a><span class="ss">- </span>The notation $\psi(\P)$ means that the parameter is a function of $\P$ -- in</span>
<span id="cb20-145"><a href="#cb20-145"></a>  other words, that it is a function of this joint probability distribution</span>
<span id="cb20-146"><a href="#cb20-146"></a><span class="ss">- </span>This means that we can compute it for any distribution $\P$</span>
<span id="cb20-147"><a href="#cb20-147"></a><span class="ss">- </span>For example, if we know the true $\P(W,A,M,Y)$, we can comnpute the true value</span>
<span id="cb20-148"><a href="#cb20-148"></a>  of the parameter by:</span>
<span id="cb20-149"><a href="#cb20-149"></a><span class="ss">  - </span>Computing the conditional expectation $\E(Y\mid A=1,M=m,W=w)$ for all values</span>
<span id="cb20-150"><a href="#cb20-150"></a>    $(m,w)$</span>
<span id="cb20-151"><a href="#cb20-151"></a><span class="ss">  - </span>Computing the conditional expectation $\E(Y\mid A=0,M=m,W=w)$ for all values</span>
<span id="cb20-152"><a href="#cb20-152"></a>    $(m,w)$</span>
<span id="cb20-153"><a href="#cb20-153"></a><span class="ss">  - </span>Computing the probability $\P(M=m\mid A=0,W=w)$ for all values $(m,w)$</span>
<span id="cb20-154"><a href="#cb20-154"></a><span class="ss">  - </span>Compute</span>
<span id="cb20-155"><a href="#cb20-155"></a>    \begin{align*}</span>
<span id="cb20-156"><a href="#cb20-156"></a>      \color{Goldenrod}{\E<span class="sc">\{</span>}&amp;\color{ForestGreen}{\E(Y \mid A=1, M, W) -</span>
<span id="cb20-157"><a href="#cb20-157"></a>        \E(Y \mid A=0, M, W)}\color{Goldenrod}{\mid A=0,W<span class="sc">\}</span>} =<span class="sc">\\</span></span>
<span id="cb20-158"><a href="#cb20-158"></a>      &amp;\color{Goldenrod}{\sum_m\color{ForestGreen}{<span class="sc">\{</span>\E(Y \mid A=1, m, w) -</span>
<span id="cb20-159"><a href="#cb20-159"></a>        \E(Y \mid A=0, m, w)<span class="sc">\}</span>} \P(M=m\mid A=0, W=w)}</span>
<span id="cb20-160"><a href="#cb20-160"></a>    \end{align*}</span>
<span id="cb20-161"><a href="#cb20-161"></a><span class="ss">  - </span>Computing the probability $\P(W=w)$ for all values $w$</span>
<span id="cb20-162"><a href="#cb20-162"></a><span class="ss">  - </span>Computing the mean over all values $w$</span>
<span id="cb20-163"><a href="#cb20-163"></a></span>
<span id="cb20-164"><a href="#cb20-164"></a></span>
<span id="cb20-165"><a href="#cb20-165"></a><span class="fu">## Plug-in (a.k.a g-computation) estimator</span></span>
<span id="cb20-166"><a href="#cb20-166"></a></span>
<span id="cb20-167"><a href="#cb20-167"></a>The above is how you would compute the _true value_ __if you know__ the true</span>
<span id="cb20-168"><a href="#cb20-168"></a>distribution $\P$</span>
<span id="cb20-169"><a href="#cb20-169"></a></span>
<span id="cb20-170"><a href="#cb20-170"></a><span class="ss">- </span>This is exactly what we did in our R examples before</span>
<span id="cb20-171"><a href="#cb20-171"></a><span class="ss">- </span>But we can use the same logic for estimation:</span>
<span id="cb20-172"><a href="#cb20-172"></a><span class="ss">  - </span>Fit a regression to estimate, say $\hat\E(Y\mid A=1,M=m,W=w)$</span>
<span id="cb20-173"><a href="#cb20-173"></a><span class="ss">  - </span>Fit a regression to estimate, say $\hat\E(Y\mid A=0,M=m,W=w)$</span>
<span id="cb20-174"><a href="#cb20-174"></a><span class="ss">  - </span>Fit a regression to estimate, say $\hat\P(M=m\mid A=0,W=w)$</span>
<span id="cb20-175"><a href="#cb20-175"></a><span class="ss">  - </span>Estimate $\P(W=w)$ with the empirical distribution</span>
<span id="cb20-176"><a href="#cb20-176"></a><span class="ss">  - </span>Evaluate</span>
<span id="cb20-177"><a href="#cb20-177"></a>    $$</span>
<span id="cb20-178"><a href="#cb20-178"></a>      \psi(\hat\P) = \hat{\E}[\color{RoyalBlue}{</span>
<span id="cb20-179"><a href="#cb20-179"></a>        \hat{\E}<span class="sc">\{</span>\color{Goldenrod}{\hat\E(Y \mid A=1, M, W) -</span>
<span id="cb20-180"><a href="#cb20-180"></a>        \hat{\E}(Y \mid A=0, M, W)}\mid A=0,W<span class="sc">\}</span>}]</span>
<span id="cb20-181"><a href="#cb20-181"></a>    $$</span>
<span id="cb20-182"><a href="#cb20-182"></a><span class="ss">- </span>This is known as the G-computation estimator.</span>
<span id="cb20-183"><a href="#cb20-183"></a></span>
<span id="cb20-184"><a href="#cb20-184"></a><span class="fu">## First weighted estimator (akin to inverse probability weighted)</span></span>
<span id="cb20-185"><a href="#cb20-185"></a></span>
<span id="cb20-186"><a href="#cb20-186"></a><span class="ss">- </span>An alternative expression of the parameter functional (for the NDE) is given</span>
<span id="cb20-187"><a href="#cb20-187"></a>  by</span>
<span id="cb20-188"><a href="#cb20-188"></a>  $$</span>
<span id="cb20-189"><a href="#cb20-189"></a>    \E \bigg[\color{RoyalBlue}{\bigg<span class="sc">\{</span> \frac{\I(A=1)}{\P(A=1\mid W)}</span>
<span id="cb20-190"><a href="#cb20-190"></a>    \frac{\P(M\mid A=0,W)}{\P(M\mid A=1,W)} -</span>
<span id="cb20-191"><a href="#cb20-191"></a>    \frac{\I(A=0)}{\P(A=0\mid W)}\bigg<span class="sc">\}</span>} \times \color{Goldenrod}{Y}\bigg]</span>
<span id="cb20-192"><a href="#cb20-192"></a>  $$</span>
<span id="cb20-193"><a href="#cb20-193"></a><span class="ss">- </span>Thus, you can also construct a weighted estimator as</span>
<span id="cb20-194"><a href="#cb20-194"></a>  $$</span>
<span id="cb20-195"><a href="#cb20-195"></a>    \frac{1}{n} \sum_{i=1}^n \bigg[\color{RoyalBlue}{\bigg<span class="sc">\{</span></span>
<span id="cb20-196"><a href="#cb20-196"></a>    \frac{\I(A_i=1)}{\hat{\P}(A_i=1\mid W_i)}</span>
<span id="cb20-197"><a href="#cb20-197"></a>    \frac{\hat{\P}(M_i\mid A_i=0,W_i)}{\hat{\P}(M_i\mid A_i=1, W_i)} -</span>
<span id="cb20-198"><a href="#cb20-198"></a>    \frac{\I(A_i=0)}{\hat{\P}(A_i=0\mid W_i)}\bigg<span class="sc">\}</span>} \times</span>
<span id="cb20-199"><a href="#cb20-199"></a>    \color{Goldenrod}{Y_i} \bigg]</span>
<span id="cb20-200"><a href="#cb20-200"></a>  $$</span>
<span id="cb20-201"><a href="#cb20-201"></a></span>
<span id="cb20-202"><a href="#cb20-202"></a><span class="fu">## Second weighted estimator</span></span>
<span id="cb20-203"><a href="#cb20-203"></a></span>
<span id="cb20-204"><a href="#cb20-204"></a><span class="ss">- </span>The parameter functional for the NDE can also be expressed as a combination of</span>
<span id="cb20-205"><a href="#cb20-205"></a>  regression and weighting:</span>
<span id="cb20-206"><a href="#cb20-206"></a>  $$</span>
<span id="cb20-207"><a href="#cb20-207"></a>    \E\bigg[\color{RoyalBlue}{\frac{\I(A=0)}{\P(A=0\mid W)}}</span>
<span id="cb20-208"><a href="#cb20-208"></a>    \times \color{Goldenrod}{\E(Y \mid A=1, M, W) -</span>
<span id="cb20-209"><a href="#cb20-209"></a>    \E(Y \mid A=0, M, W)}\bigg]</span>
<span id="cb20-210"><a href="#cb20-210"></a>  $$</span>
<span id="cb20-211"><a href="#cb20-211"></a></span>
<span id="cb20-212"><a href="#cb20-212"></a><span class="ss">- </span>Thus, you can also construct a weighted estimator as</span>
<span id="cb20-213"><a href="#cb20-213"></a>  $$</span>
<span id="cb20-214"><a href="#cb20-214"></a>    \frac{1}{n} \sum_{i=1}^n \bigg[\color{RoyalBlue}{</span>
<span id="cb20-215"><a href="#cb20-215"></a>    \frac{\I(A_i=0)}{\hat{\P}(A_i=0\mid W_i)}} \times</span>
<span id="cb20-216"><a href="#cb20-216"></a>    \color{Goldenrod}{\hat{\E}(Y \mid A=1, M_i, W_i) -</span>
<span id="cb20-217"><a href="#cb20-217"></a>    \hat{\E}(Y \mid A=0, M_i, W_i)}\bigg]</span>
<span id="cb20-218"><a href="#cb20-218"></a>  $$</span>
<span id="cb20-219"><a href="#cb20-219"></a></span>
<span id="cb20-220"><a href="#cb20-220"></a><span class="fu">## How can g-estimation and weighted estimation be implemented in practice?</span></span>
<span id="cb20-221"><a href="#cb20-221"></a></span>
<span id="cb20-222"><a href="#cb20-222"></a><span class="ss">- </span>There are two possible ways to do G-computation or weighted estimation:</span>
<span id="cb20-223"><a href="#cb20-223"></a><span class="ss">  - </span>Using parametric models for the above regressions</span>
<span id="cb20-224"><a href="#cb20-224"></a><span class="ss">  - </span>Using flexible data-adaptive regression (aka machine learning)</span>
<span id="cb20-225"><a href="#cb20-225"></a></span>
<span id="cb20-226"><a href="#cb20-226"></a><span class="fu">## Pros and cons of G-computation and weighting parametric models</span></span>
<span id="cb20-227"><a href="#cb20-227"></a></span>
<span id="cb20-228"><a href="#cb20-228"></a><span class="ss">- </span>Pros:</span>
<span id="cb20-229"><a href="#cb20-229"></a><span class="ss">  - </span>Easy to understand</span>
<span id="cb20-230"><a href="#cb20-230"></a><span class="ss">  - </span>Ease of implementation (standard regression software)</span>
<span id="cb20-231"><a href="#cb20-231"></a><span class="ss">  - </span>Can use the Delta method or the bootstrap for computation of standard errors</span>
<span id="cb20-232"><a href="#cb20-232"></a></span>
<span id="cb20-233"><a href="#cb20-233"></a><span class="ss">- </span>Cons:</span>
<span id="cb20-234"><a href="#cb20-234"></a><span class="ss">  - </span>Unless $W$ and $M$ contain very few categorical variables, it is very easy</span>
<span id="cb20-235"><a href="#cb20-235"></a>    to misspecify the models</span>
<span id="cb20-236"><a href="#cb20-236"></a><span class="ss">  - </span>This can introduce sizable bias in the estimators</span>
<span id="cb20-237"><a href="#cb20-237"></a><span class="ss">  - </span>This modelling assumptions have become less necessary in the presence of</span>
<span id="cb20-238"><a href="#cb20-238"></a>    data-adaptive regression tools (a.k.a., machine learning)</span>
<span id="cb20-239"><a href="#cb20-239"></a></span>
<span id="cb20-240"><a href="#cb20-240"></a><span class="fu">## An example of the bias of a g-computation estimator of the natural direct effect</span></span>
<span id="cb20-241"><a href="#cb20-241"></a></span>
<span id="cb20-242"><a href="#cb20-242"></a><span class="ss">- </span>The following <span class="in">`R`</span> chunk provides simulation code to exemplify the bias of a</span>
<span id="cb20-243"><a href="#cb20-243"></a>  G-computation parametric estimator in a simple situation</span>
<span id="cb20-244"><a href="#cb20-244"></a></span>
<span id="cb20-245"><a href="#cb20-245"></a>  <span class="in">```{r}</span></span>
<span id="cb20-246"><a href="#cb20-246"></a><span class="in">  mean_y &lt;- function(m, a, w) abs(w) + a * m</span></span>
<span id="cb20-247"><a href="#cb20-247"></a><span class="in">  mean_m &lt;- function(a, w) plogis(w^2 - a)</span></span>
<span id="cb20-248"><a href="#cb20-248"></a><span class="in">  pscore &lt;- function(w) plogis(1 - abs(w))</span></span>
<span id="cb20-249"><a href="#cb20-249"></a><span class="in">  ```</span></span>
<span id="cb20-250"><a href="#cb20-250"></a></span>
<span id="cb20-251"><a href="#cb20-251"></a>  <span class="in">```{r}</span></span>
<span id="cb20-252"><a href="#cb20-252"></a><span class="in">  #| echo: false</span></span>
<span id="cb20-253"><a href="#cb20-253"></a><span class="in">  #| results: hide</span></span>
<span id="cb20-254"><a href="#cb20-254"></a><span class="in">  w_big &lt;- runif(1e6, -1, 1)</span></span>
<span id="cb20-255"><a href="#cb20-255"></a><span class="in">  trueval &lt;- mean((mean_y(1, 1, w_big) - mean_y(1, 0, w_big)) *</span></span>
<span id="cb20-256"><a href="#cb20-256"></a><span class="in">    mean_m(0, w_big) + (mean_y(0, 1, w_big) - mean_y(0, 0, w_big)) *</span></span>
<span id="cb20-257"><a href="#cb20-257"></a><span class="in">      (1 - mean_m(0, w_big)))</span></span>
<span id="cb20-258"><a href="#cb20-258"></a><span class="in">  print(trueval)</span></span>
<span id="cb20-259"><a href="#cb20-259"></a><span class="in">  ```</span></span>
<span id="cb20-260"><a href="#cb20-260"></a></span>
<span id="cb20-261"><a href="#cb20-261"></a><span class="ss">- </span>This yields a true NDE value of <span class="in">`r round(trueval, 4)`</span></span>
<span id="cb20-262"><a href="#cb20-262"></a></span>
<span id="cb20-263"><a href="#cb20-263"></a><span class="ss">- </span>Let's perform a simulation where we draw 1000 datasets from the above</span>
<span id="cb20-264"><a href="#cb20-264"></a>  distribution, and compute a g-computation estimator based on</span>
<span id="cb20-265"><a href="#cb20-265"></a></span>
<span id="cb20-266"><a href="#cb20-266"></a>  <span class="in">```{r}</span></span>
<span id="cb20-267"><a href="#cb20-267"></a><span class="in">  gcomp &lt;- function(y, m, a, w) {</span></span>
<span id="cb20-268"><a href="#cb20-268"></a><span class="in">    lm_y &lt;- lm(y ~ m + a + w)</span></span>
<span id="cb20-269"><a href="#cb20-269"></a><span class="in">    pred_y1 &lt;- predict(lm_y, newdata = data.frame(a = 1, m = m, w = w))</span></span>
<span id="cb20-270"><a href="#cb20-270"></a><span class="in">    pred_y0 &lt;- predict(lm_y, newdata = data.frame(a = 0, m = m, w = w))</span></span>
<span id="cb20-271"><a href="#cb20-271"></a><span class="in">    pseudo &lt;- pred_y1 - pred_y0</span></span>
<span id="cb20-272"><a href="#cb20-272"></a><span class="in">    lm_pseudo &lt;- lm(pseudo ~ a + w)</span></span>
<span id="cb20-273"><a href="#cb20-273"></a><span class="in">    pred_pseudo &lt;- predict(lm_pseudo, newdata = data.frame(a = 0, w = w))</span></span>
<span id="cb20-274"><a href="#cb20-274"></a><span class="in">    estimate &lt;- mean(pred_pseudo)</span></span>
<span id="cb20-275"><a href="#cb20-275"></a><span class="in">    return(estimate)</span></span>
<span id="cb20-276"><a href="#cb20-276"></a><span class="in">  }</span></span>
<span id="cb20-277"><a href="#cb20-277"></a><span class="in">  ```</span></span>
<span id="cb20-278"><a href="#cb20-278"></a></span>
<span id="cb20-279"><a href="#cb20-279"></a>  <span class="in">```{r}</span></span>
<span id="cb20-280"><a href="#cb20-280"></a><span class="in">  estimate &lt;- lapply(seq_len(1000), function(iter) {</span></span>
<span id="cb20-281"><a href="#cb20-281"></a><span class="in">    n &lt;- 1000</span></span>
<span id="cb20-282"><a href="#cb20-282"></a><span class="in">    w &lt;- runif(n, -1, 1)</span></span>
<span id="cb20-283"><a href="#cb20-283"></a><span class="in">    a &lt;- rbinom(n, 1, pscore(w))</span></span>
<span id="cb20-284"><a href="#cb20-284"></a><span class="in">    m &lt;- rbinom(n, 1, mean_m(a, w))</span></span>
<span id="cb20-285"><a href="#cb20-285"></a><span class="in">    y &lt;- rnorm(n, mean_y(m, a, w))</span></span>
<span id="cb20-286"><a href="#cb20-286"></a><span class="in">    est &lt;- gcomp(y, m, a, w)</span></span>
<span id="cb20-287"><a href="#cb20-287"></a><span class="in">    return(est)</span></span>
<span id="cb20-288"><a href="#cb20-288"></a><span class="in">  })</span></span>
<span id="cb20-289"><a href="#cb20-289"></a><span class="in">  estimate &lt;- do.call(c, estimate)</span></span>
<span id="cb20-290"><a href="#cb20-290"></a></span>
<span id="cb20-291"><a href="#cb20-291"></a><span class="in">  hist(estimate)</span></span>
<span id="cb20-292"><a href="#cb20-292"></a><span class="in">  abline(v = trueval, col = "red", lwd = 4)</span></span>
<span id="cb20-293"><a href="#cb20-293"></a><span class="in">  ```</span></span>
<span id="cb20-294"><a href="#cb20-294"></a></span>
<span id="cb20-295"><a href="#cb20-295"></a><span class="ss">- </span>The bias also affects the confidence intervals:</span>
<span id="cb20-296"><a href="#cb20-296"></a></span>
<span id="cb20-297"><a href="#cb20-297"></a>  <span class="in">```{r}</span></span>
<span id="cb20-298"><a href="#cb20-298"></a><span class="in">  #| fig-width: 8</span></span>
<span id="cb20-299"><a href="#cb20-299"></a><span class="in">  cis &lt;- cbind(</span></span>
<span id="cb20-300"><a href="#cb20-300"></a><span class="in">    estimate - qnorm(0.975) * sd(estimate),</span></span>
<span id="cb20-301"><a href="#cb20-301"></a><span class="in">    estimate + qnorm(0.975) * sd(estimate)</span></span>
<span id="cb20-302"><a href="#cb20-302"></a><span class="in">  )</span></span>
<span id="cb20-303"><a href="#cb20-303"></a></span>
<span id="cb20-304"><a href="#cb20-304"></a><span class="in">  ord &lt;- order(rowSums(cis))</span></span>
<span id="cb20-305"><a href="#cb20-305"></a><span class="in">  lower &lt;- cis[ord, 1]</span></span>
<span id="cb20-306"><a href="#cb20-306"></a><span class="in">  upper &lt;- cis[ord, 2]</span></span>
<span id="cb20-307"><a href="#cb20-307"></a><span class="in">  curve(trueval + 0 * x,</span></span>
<span id="cb20-308"><a href="#cb20-308"></a><span class="in">    ylim = c(0, 1), xlim = c(0, 1001), lwd = 2, lty = 3, xaxt = "n",</span></span>
<span id="cb20-309"><a href="#cb20-309"></a><span class="in">    xlab = "", ylab = "Confidence interval", cex.axis = 1.2, cex.lab = 1.2</span></span>
<span id="cb20-310"><a href="#cb20-310"></a><span class="in">  )</span></span>
<span id="cb20-311"><a href="#cb20-311"></a><span class="in">  for (i in 1:1000) {</span></span>
<span id="cb20-312"><a href="#cb20-312"></a><span class="in">    clr &lt;- rgb(0.5, 0, 0.75, 0.5)</span></span>
<span id="cb20-313"><a href="#cb20-313"></a><span class="in">    if (upper[i] &lt; trueval || lower[i] &gt; trueval) clr &lt;- rgb(1, 0, 0, 1)</span></span>
<span id="cb20-314"><a href="#cb20-314"></a><span class="in">    points(rep(i, 2), c(lower[i], upper[i]), type = "l", lty = 1, col = clr)</span></span>
<span id="cb20-315"><a href="#cb20-315"></a><span class="in">  }</span></span>
<span id="cb20-316"><a href="#cb20-316"></a><span class="in">  text(450, 0.10, "n=1000 repetitions = 1000 ", cex = 1.2)</span></span>
<span id="cb20-317"><a href="#cb20-317"></a><span class="in">  text(450, 0.01, paste0(</span></span>
<span id="cb20-318"><a href="#cb20-318"></a><span class="in">    "Coverage probability = ",</span></span>
<span id="cb20-319"><a href="#cb20-319"></a><span class="in">    mean(lower &lt; trueval &amp; trueval &lt; upper), "%"</span></span>
<span id="cb20-320"><a href="#cb20-320"></a><span class="in">  ), cex = 1.2)</span></span>
<span id="cb20-321"><a href="#cb20-321"></a><span class="in">  ```</span></span>
<span id="cb20-322"><a href="#cb20-322"></a></span>
<span id="cb20-323"><a href="#cb20-323"></a><span class="fu">## Pros and cons of G-computation or weighting with data-adaptive regression</span></span>
<span id="cb20-324"><a href="#cb20-324"></a></span>
<span id="cb20-325"><a href="#cb20-325"></a><span class="ss">- </span>Pros:</span>
<span id="cb20-326"><a href="#cb20-326"></a><span class="ss">  - </span>Easy to understand.</span>
<span id="cb20-327"><a href="#cb20-327"></a><span class="ss">  - </span>Alleviate model-misspecification bias.</span>
<span id="cb20-328"><a href="#cb20-328"></a></span>
<span id="cb20-329"><a href="#cb20-329"></a><span class="ss">- </span>Cons:</span>
<span id="cb20-330"><a href="#cb20-330"></a><span class="ss">  - </span>Might be harder to implement depending on the regression procedures used.</span>
<span id="cb20-331"><a href="#cb20-331"></a><span class="ss">  - </span>No general approaches for computation of standard errors and confidence</span>
<span id="cb20-332"><a href="#cb20-332"></a>    intervals.</span>
<span id="cb20-333"><a href="#cb20-333"></a><span class="ss">  - </span>For example, the bootstrap is not guaranteed to work, and it is known to</span>
<span id="cb20-334"><a href="#cb20-334"></a>    fail in some cases.</span>
<span id="cb20-335"><a href="#cb20-335"></a></span>
<span id="cb20-336"><a href="#cb20-336"></a></span>
<span id="cb20-337"><a href="#cb20-337"></a><span class="fu">## Solution to these problems: robust semiparametric efficient estimation</span></span>
<span id="cb20-338"><a href="#cb20-338"></a></span>
<span id="cb20-339"><a href="#cb20-339"></a><span class="ss">- </span>Intuitively, it combines the three above estimators to obtain an</span>
<span id="cb20-340"><a href="#cb20-340"></a>  estimator with improved robustness properties</span>
<span id="cb20-341"><a href="#cb20-341"></a><span class="ss">- </span>It offers a way to use data-adaptive regression to</span>
<span id="cb20-342"><a href="#cb20-342"></a><span class="ss">  - </span>avoid model misspecification bias,</span>
<span id="cb20-343"><a href="#cb20-343"></a><span class="ss">  - </span>endow the estimators with additional robustness (e.g., multiple robustness),</span>
<span id="cb20-344"><a href="#cb20-344"></a>    while</span>
<span id="cb20-345"><a href="#cb20-345"></a><span class="ss">  - </span>allowing the computation of correct standard errors and confidence</span>
<span id="cb20-346"><a href="#cb20-346"></a>  intervals using Gaussian approximations</span>
<span id="cb20-347"><a href="#cb20-347"></a></span>
<span id="cb20-348"><a href="#cb20-348"></a><span class="co">&lt;!--</span></span>
<span id="cb20-349"><a href="#cb20-349"></a><span class="co"> - This can be achieved by adding a bias correction factor the the</span></span>
<span id="cb20-350"><a href="#cb20-350"></a><span class="co">   G-computation as follows:</span></span>
<span id="cb20-351"><a href="#cb20-351"></a><span class="co">   \begin{equation*}</span></span>
<span id="cb20-352"><a href="#cb20-352"></a><span class="co">     \psi(\hat \P) + \frac{1}{n}\sum_{i=1}^n D(O_i)</span></span>
<span id="cb20-353"><a href="#cb20-353"></a><span class="co">   \end{equation*}</span></span>
<span id="cb20-354"><a href="#cb20-354"></a><span class="co">   for some function $D(O_i)$ of the data</span></span>
<span id="cb20-355"><a href="#cb20-355"></a><span class="co"> - The function $D(O)$ is called _the efficient influence function_ (EIF)</span></span>
<span id="cb20-356"><a href="#cb20-356"></a><span class="co"> - The EIF must be found on a case-by-case basis for each parameter $\psi(\P)$</span></span>
<span id="cb20-357"><a href="#cb20-357"></a><span class="co"> - For example, for estimating the standardized mean $\psi(\P)=\E[\E(Y\mid A=1,</span></span>
<span id="cb20-358"><a href="#cb20-358"></a><span class="co">   W)]$, we have</span></span>
<span id="cb20-359"><a href="#cb20-359"></a><span class="co">   \begin{equation*}</span></span>
<span id="cb20-360"><a href="#cb20-360"></a><span class="co">     D(O) = \frac{A}{\hat \P(A=1\mid W)}[Y - \hat\E(Y\mid A=1, W)] +</span></span>
<span id="cb20-361"><a href="#cb20-361"></a><span class="co">     \hat\E(Y\mid A=1, W) - \psi(\hat\P)</span></span>
<span id="cb20-362"><a href="#cb20-362"></a><span class="co">   \end{equation*}</span></span>
<span id="cb20-363"><a href="#cb20-363"></a><span class="co"> - The EIF is found by using a distributional analogue of a Taylor expansion</span></span>
<span id="cb20-364"><a href="#cb20-364"></a><span class="co"> - In this workshop we will omit the specific form of $D(O)$ for</span></span>
<span id="cb20-365"><a href="#cb20-365"></a><span class="co">   some of the parameters that we use</span></span>
<span id="cb20-366"><a href="#cb20-366"></a><span class="co"> - But the estimators we discuss and implement in the R packages will be based</span></span>
<span id="cb20-367"><a href="#cb20-367"></a><span class="co">   on these EIFs</span></span>
<span id="cb20-368"><a href="#cb20-368"></a><span class="co"> - And the specific form of the EIF may be found in papers in the references</span></span>
<span id="cb20-369"><a href="#cb20-369"></a></span>
<span id="cb20-370"><a href="#cb20-370"></a><span class="co"> Note: the bias correction above may have an additional problem of</span></span>
<span id="cb20-371"><a href="#cb20-371"></a><span class="co"> returning parameter estimates outside of natural bounds. For example,</span></span>
<span id="cb20-372"><a href="#cb20-372"></a><span class="co"> probabilities greater than one. A solution to this (not discussed in</span></span>
<span id="cb20-373"><a href="#cb20-373"></a><span class="co"> this workshop but implemented in some of the R packages) is targeted</span></span>
<span id="cb20-374"><a href="#cb20-374"></a><span class="co"> minimum loss-based estimation.</span></span>
<span id="cb20-375"><a href="#cb20-375"></a><span class="co">--&gt;</span></span>
<span id="cb20-376"><a href="#cb20-376"></a></span>
<span id="cb20-377"><a href="#cb20-377"></a><span class="fu"># Construction of a semiparametric efficient estimator for the NDE (a.k.a. the one-step estimator)</span></span>
<span id="cb20-378"><a href="#cb20-378"></a></span>
<span id="cb20-379"><a href="#cb20-379"></a><span class="co">&lt;!--</span></span>
<span id="cb20-380"><a href="#cb20-380"></a><span class="co">- For illustration, we will first present how to construct an estimator of the</span></span>
<span id="cb20-381"><a href="#cb20-381"></a><span class="co">  NDE that uses the EIF "by hand"</span></span>
<span id="cb20-382"><a href="#cb20-382"></a><span class="co">--&gt;</span></span>
<span id="cb20-383"><a href="#cb20-383"></a><span class="ss">- </span>Here we show the detail of how to construct an estimator for the NDE for</span>
<span id="cb20-384"><a href="#cb20-384"></a>  illustration, but the construction of this estimator is a bit involved and may</span>
<span id="cb20-385"><a href="#cb20-385"></a>  be complex in daily research practice</span>
<span id="cb20-386"><a href="#cb20-386"></a><span class="ss">- </span>For practice, we will teach you how to use our packages _medoutcon_ (and</span>
<span id="cb20-387"><a href="#cb20-387"></a>  _medshift_, as detailed in the extra material) for automatic implementation of</span>
<span id="cb20-388"><a href="#cb20-388"></a>  these estimators of the NDE and other parameters</span>
<span id="cb20-389"><a href="#cb20-389"></a></span>
<span id="cb20-390"><a href="#cb20-390"></a>First, we need to introduce some notation to describe the EIF for the NDE</span>
<span id="cb20-391"><a href="#cb20-391"></a></span>
<span id="cb20-392"><a href="#cb20-392"></a><span class="ss">- </span>Let $Q(M, W)$ denote $\E(Y\mid A=1, M, W) - \E(Y\mid A=0, M, W)$</span>
<span id="cb20-393"><a href="#cb20-393"></a><span class="ss">- </span>We can now introduce the semiparametric efficient estimator:</span>
<span id="cb20-394"><a href="#cb20-394"></a></span>
<span id="cb20-395"><a href="#cb20-395"></a>\begin{align*}</span>
<span id="cb20-396"><a href="#cb20-396"></a>    \hat{\psi} &amp;= \frac{1}{n} \sum_{i=1}^n \color{RoyalBlue}{\bigg<span class="sc">\{</span></span>
<span id="cb20-397"><a href="#cb20-397"></a>      \frac{\I(A_i=1)}{\hat{\P}(A_i=1 \mid W_i)}</span>
<span id="cb20-398"><a href="#cb20-398"></a>      \frac{\hat{\P}(M_i \mid A_i=0,W)_i}{\hat{\P}(M_i \mid A_i=1,W_i)} -</span>
<span id="cb20-399"><a href="#cb20-399"></a>      \frac{\I(A=0)}{\hat{\P}(A_i=0 \mid W_i)}\bigg<span class="sc">\}</span>}</span>
<span id="cb20-400"><a href="#cb20-400"></a>      \color{Goldenrod}{<span class="co">[</span><span class="ot">Y_i - \hat{\E}(Y\mid A_i,M_i,W_i)</span><span class="co">]</span>} <span class="sc">\\</span></span>
<span id="cb20-401"><a href="#cb20-401"></a>    &amp;+ \frac{1}{n} \sum_{i=1}^n \color{RoyalBlue}{\frac{\I(A=0)}{\P(A=0 \mid</span>
<span id="cb20-402"><a href="#cb20-402"></a>      W)}} \color{Goldenrod}{\big<span class="sc">\{</span> \hat{Q}(M_i,W_i) -</span>
<span id="cb20-403"><a href="#cb20-403"></a>      \hat{\E}<span class="co">[</span><span class="ot">\hat{Q}(M_i,W_i) \mid W_i, A_i = 0</span><span class="co">]</span> \big<span class="sc">\}</span>} <span class="sc">\\</span></span>
<span id="cb20-404"><a href="#cb20-404"></a>    &amp;+ \frac{1}{n} \sum_{i=1}^n \color{Goldenrod}{</span>
<span id="cb20-405"><a href="#cb20-405"></a>      \hat{\E}<span class="co">[</span><span class="ot">\hat{Q}(M_i,W_i) \mid W_i,A_i=0</span><span class="co">]</span>}</span>
<span id="cb20-406"><a href="#cb20-406"></a>\end{align*}</span>
<span id="cb20-407"><a href="#cb20-407"></a></span>
<span id="cb20-408"><a href="#cb20-408"></a><span class="ss">- </span>In this estimator, you can recognize elements from the G-computation estimator</span>
<span id="cb20-409"><a href="#cb20-409"></a>  and the weighted estimators:</span>
<span id="cb20-410"><a href="#cb20-410"></a><span class="ss">  - </span>The third line is the G-computation estimator</span>
<span id="cb20-411"><a href="#cb20-411"></a><span class="ss">  - </span>The second line is a centered version of the second weighted estimator</span>
<span id="cb20-412"><a href="#cb20-412"></a><span class="ss">  - </span>The first line is a centered version of the first weighted estimator</span>
<span id="cb20-413"><a href="#cb20-413"></a></span>
<span id="cb20-414"><a href="#cb20-414"></a><span class="ss">- </span>Estimating $\P(M\mid A, W)$ is a very challenging problem when $M$ is</span>
<span id="cb20-415"><a href="#cb20-415"></a>  high-dimensional. But, since we have the ratio of these conditional densities,</span>
<span id="cb20-416"><a href="#cb20-416"></a>  we can re-paramterize using Bayes' rule to get something that is easier to</span>
<span id="cb20-417"><a href="#cb20-417"></a>  compute:</span>
<span id="cb20-418"><a href="#cb20-418"></a>  \begin{equation*}</span>
<span id="cb20-419"><a href="#cb20-419"></a>    \frac{\P(M \mid A=0, W)}{\P(M \mid A=1,W)} = \frac{\P(A = 0 \mid M, W)</span>
<span id="cb20-420"><a href="#cb20-420"></a>      \P(A=1 \mid W)}{\P(A = 1 \mid M, W) \P(A=0 \mid W)} \ .</span>
<span id="cb20-421"><a href="#cb20-421"></a>  \end{equation*}</span>
<span id="cb20-422"><a href="#cb20-422"></a></span>
<span id="cb20-423"><a href="#cb20-423"></a>Thus we can change the expression of the estimator a bit as follows. First, some</span>
<span id="cb20-424"><a href="#cb20-424"></a>more notation that will be useful later:</span>
<span id="cb20-425"><a href="#cb20-425"></a></span>
<span id="cb20-426"><a href="#cb20-426"></a><span class="ss">- </span>Let $g(a\mid w)$ denote $\P(A=a\mid W=w)$</span>
<span id="cb20-427"><a href="#cb20-427"></a><span class="ss">- </span>Let $e(a\mid m, w)$ denote $\P(A=a\mid M=m, W=w)$</span>
<span id="cb20-428"><a href="#cb20-428"></a><span class="ss">- </span>Let $b(a, m, w)$ denote $\E(Y\mid A=a, M=m, W=w)$</span>
<span id="cb20-429"><a href="#cb20-429"></a><span class="ss">- </span>The quantity being averaged can be re-expressed as follows</span>
<span id="cb20-430"><a href="#cb20-430"></a></span>
<span id="cb20-431"><a href="#cb20-431"></a>\begin{align*}</span>
<span id="cb20-432"><a href="#cb20-432"></a>    &amp; \color{RoyalBlue}{\bigg<span class="sc">\{</span> \frac{\I(A=1)}{g(0\mid W)}</span>
<span id="cb20-433"><a href="#cb20-433"></a>      \frac{e(0\mid M,W)}{e(1\mid M,W)} - \frac{\I(A=0)}{g(0\mid W)}\bigg<span class="sc">\}</span>}</span>
<span id="cb20-434"><a href="#cb20-434"></a>      \times \color{Goldenrod}{<span class="co">[</span><span class="ot">Y - b(A,M,W)</span><span class="co">]</span>} <span class="sc">\\</span></span>
<span id="cb20-435"><a href="#cb20-435"></a>    &amp;+ \color{RoyalBlue}{\frac{\I(A=0)}{g(0\mid W)}}</span>
<span id="cb20-436"><a href="#cb20-436"></a>      \color{Goldenrod}{\big<span class="sc">\{</span>Q(M,W) - \E<span class="co">[</span><span class="ot">Q(M,W) \mid W, A=0</span><span class="co">]</span> \big<span class="sc">\}</span>} <span class="sc">\\</span></span>
<span id="cb20-437"><a href="#cb20-437"></a>    &amp;+ \color{Goldenrod}{\E<span class="co">[</span><span class="ot">Q(M,W) \mid W, A=0</span><span class="co">]</span>}</span>
<span id="cb20-438"><a href="#cb20-438"></a>\end{align*}</span>
<span id="cb20-439"><a href="#cb20-439"></a></span>
<span id="cb20-440"><a href="#cb20-440"></a><span class="fu">## How to compute the one-step estimator (akin to Augmented IPW)</span></span>
<span id="cb20-441"><a href="#cb20-441"></a></span>
<span id="cb20-442"><a href="#cb20-442"></a>First we will generate some data:</span>
<span id="cb20-445"><a href="#cb20-445"></a><span class="in">```{r}</span></span>
<span id="cb20-446"><a href="#cb20-446"></a>mean_y <span class="ot">&lt;-</span> <span class="cf">function</span>(m, a, w) <span class="fu">abs</span>(w) <span class="sc">+</span> a <span class="sc">*</span> m</span>
<span id="cb20-447"><a href="#cb20-447"></a>mean_m <span class="ot">&lt;-</span> <span class="cf">function</span>(a, w)<span class="fu">plogis</span>(w<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> a)</span>
<span id="cb20-448"><a href="#cb20-448"></a>pscore <span class="ot">&lt;-</span> <span class="cf">function</span>(w) <span class="fu">plogis</span>(<span class="dv">1</span> <span class="sc">-</span> <span class="fu">abs</span>(w))</span>
<span id="cb20-449"><a href="#cb20-449"></a></span>
<span id="cb20-450"><a href="#cb20-450"></a>w_big <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-451"><a href="#cb20-451"></a>trueval <span class="ot">&lt;-</span> <span class="fu">mean</span>((<span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)</span>
<span id="cb20-452"><a href="#cb20-452"></a>                <span class="sc">+</span> (<span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span></span>
<span id="cb20-453"><a href="#cb20-453"></a>                  (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)))</span>
<span id="cb20-454"><a href="#cb20-454"></a></span>
<span id="cb20-455"><a href="#cb20-455"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb20-456"><a href="#cb20-456"></a>w <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-457"><a href="#cb20-457"></a>a <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">pscore</span>(w))</span>
<span id="cb20-458"><a href="#cb20-458"></a>m <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">mean_m</span>(a, w))</span>
<span id="cb20-459"><a href="#cb20-459"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="fu">mean_y</span>(m, a, w))</span>
<span id="cb20-460"><a href="#cb20-460"></a><span class="in">```</span></span>
<span id="cb20-461"><a href="#cb20-461"></a></span>
<span id="cb20-462"><a href="#cb20-462"></a>Recall that the semiparametric efficient estimator can be computed  in the</span>
<span id="cb20-463"><a href="#cb20-463"></a>following steps:</span>
<span id="cb20-464"><a href="#cb20-464"></a></span>
<span id="cb20-465"><a href="#cb20-465"></a><span class="ss">1. </span>Fit models for $g(a\mid w)$, $e(a\mid m, w)$, and $b(a, m, w)$</span>
<span id="cb20-466"><a href="#cb20-466"></a><span class="ss">   - </span>In this example we will use Generalized Additive Models for tractability</span>
<span id="cb20-467"><a href="#cb20-467"></a><span class="ss">   - </span>In applied settings we recommend using an ensemble of data-adaptive</span>
<span id="cb20-468"><a href="#cb20-468"></a>     regression algorithms, such as the Super Learner <span class="co">[</span><span class="ot">@vdl2007super</span><span class="co">]</span></span>
<span id="cb20-469"><a href="#cb20-469"></a></span>
<span id="cb20-470"><a href="#cb20-470"></a>   <span class="in">```{r}</span></span>
<span id="cb20-471"><a href="#cb20-471"></a><span class="in">   library(mgcv)</span></span>
<span id="cb20-472"><a href="#cb20-472"></a><span class="in">   ## fit model for E(Y | A, W)</span></span>
<span id="cb20-473"><a href="#cb20-473"></a><span class="in">   b_fit &lt;- gam(y ~ m:a + s(w, by = a))</span></span>
<span id="cb20-474"><a href="#cb20-474"></a><span class="in">   ## fit model for P(A = 1 | M, W)</span></span>
<span id="cb20-475"><a href="#cb20-475"></a><span class="in">   e_fit &lt;- gam(a ~ m + w + s(w, by = m), family = binomial)</span></span>
<span id="cb20-476"><a href="#cb20-476"></a><span class="in">   ## fit model for P(A = 1 | W)</span></span>
<span id="cb20-477"><a href="#cb20-477"></a><span class="in">   g_fit &lt;- gam(a ~ w, family = binomial)</span></span>
<span id="cb20-478"><a href="#cb20-478"></a><span class="in">   ```</span></span>
<span id="cb20-479"><a href="#cb20-479"></a></span>
<span id="cb20-480"><a href="#cb20-480"></a><span class="ss">2. </span>Compute predictions  $g(1\mid w)$, $g(0\mid w)$, $e(1\mid m, w)$,</span>
<span id="cb20-481"><a href="#cb20-481"></a>   $e(0\mid m, w)$,$b(1, m, w)$, $b(0, m, w)$, and  $b(a, m, w)$</span>
<span id="cb20-482"><a href="#cb20-482"></a></span>
<span id="cb20-483"><a href="#cb20-483"></a>   <span class="in">```{r}</span></span>
<span id="cb20-484"><a href="#cb20-484"></a><span class="in">   ## Compute P(A = 1 | W)</span></span>
<span id="cb20-485"><a href="#cb20-485"></a><span class="in">   g1_pred &lt;- predict(g_fit, type = 'response')</span></span>
<span id="cb20-486"><a href="#cb20-486"></a><span class="in">   ## Compute P(A = 0 | W)</span></span>
<span id="cb20-487"><a href="#cb20-487"></a><span class="in">   g0_pred &lt;- 1 - g1_pred</span></span>
<span id="cb20-488"><a href="#cb20-488"></a><span class="in">   ## Compute P(A = 1 | M, W)</span></span>
<span id="cb20-489"><a href="#cb20-489"></a><span class="in">   e1_pred &lt;- predict(e_fit, type = 'response')</span></span>
<span id="cb20-490"><a href="#cb20-490"></a><span class="in">   ## Compute P(A = 0 | M, W)</span></span>
<span id="cb20-491"><a href="#cb20-491"></a><span class="in">   e0_pred &lt;- 1 - e1_pred</span></span>
<span id="cb20-492"><a href="#cb20-492"></a><span class="in">   ## Compute E(Y | A = 1, M, W)</span></span>
<span id="cb20-493"><a href="#cb20-493"></a><span class="in">   b1_pred &lt;- predict(b_fit, newdata = data.frame(a = 1, m, w))</span></span>
<span id="cb20-494"><a href="#cb20-494"></a><span class="in">   ## Compute E(Y | A = 0, M, W)</span></span>
<span id="cb20-495"><a href="#cb20-495"></a><span class="in">   b0_pred &lt;- predict(b_fit, newdata = data.frame(a = 0, m, w))</span></span>
<span id="cb20-496"><a href="#cb20-496"></a><span class="in">   ## Compute E(Y | A, M, W)</span></span>
<span id="cb20-497"><a href="#cb20-497"></a><span class="in">   b_pred  &lt;- predict(b_fit)</span></span>
<span id="cb20-498"><a href="#cb20-498"></a><span class="in">   ```</span></span>
<span id="cb20-499"><a href="#cb20-499"></a></span>
<span id="cb20-500"><a href="#cb20-500"></a><span class="ss">3. </span>Compute $Q(M, W)$, fit a model for $\E<span class="co">[</span><span class="ot">Q(M,W) \mid W,A</span><span class="co">]</span>$, and predict at</span>
<span id="cb20-501"><a href="#cb20-501"></a>   $A=0$</span>
<span id="cb20-502"><a href="#cb20-502"></a></span>
<span id="cb20-503"><a href="#cb20-503"></a>   <span class="in">```{r}</span></span>
<span id="cb20-504"><a href="#cb20-504"></a><span class="in">   ## Compute Q(M, W)</span></span>
<span id="cb20-505"><a href="#cb20-505"></a><span class="in">   pseudo &lt;- b1_pred - b0_pred</span></span>
<span id="cb20-506"><a href="#cb20-506"></a><span class="in">   ## Fit model for E[Q(M, W) | A, W]</span></span>
<span id="cb20-507"><a href="#cb20-507"></a><span class="in">   q_fit &lt;- gam(pseudo ~ a + w + s(w, by = a))</span></span>
<span id="cb20-508"><a href="#cb20-508"></a><span class="in">   ## Compute E[Q(M, W) | A = 0, W]</span></span>
<span id="cb20-509"><a href="#cb20-509"></a><span class="in">   q_pred &lt;- predict(q_fit, newdata = data.frame(a = 0, w = w))</span></span>
<span id="cb20-510"><a href="#cb20-510"></a><span class="in">   ```</span></span>
<span id="cb20-511"><a href="#cb20-511"></a></span>
<span id="cb20-512"><a href="#cb20-512"></a><span class="ss">4. </span>Estimate the weights</span>
<span id="cb20-513"><a href="#cb20-513"></a></span>
<span id="cb20-514"><a href="#cb20-514"></a>   \begin{equation*}</span>
<span id="cb20-515"><a href="#cb20-515"></a>   \color{RoyalBlue}{\bigg<span class="sc">\{</span></span>
<span id="cb20-516"><a href="#cb20-516"></a>     \frac{\I(A=1)}{g(0\mid W)} \frac{e(0 \mid M,W)}{e(1 \mid M,W)} -</span>
<span id="cb20-517"><a href="#cb20-517"></a>     \frac{\I(A=0)}{g(0\mid W)} \bigg<span class="sc">\}</span>}</span>
<span id="cb20-518"><a href="#cb20-518"></a>   \end{equation*}</span>
<span id="cb20-519"><a href="#cb20-519"></a>   using the above predictions:</span>
<span id="cb20-520"><a href="#cb20-520"></a>   <span class="in">```{r}</span></span>
<span id="cb20-521"><a href="#cb20-521"></a><span class="in">   ip_weights &lt;- a / g0_pred * e0_pred / e1_pred - (1 - a) / g0_pred</span></span>
<span id="cb20-522"><a href="#cb20-522"></a><span class="in">   ```</span></span>
<span id="cb20-523"><a href="#cb20-523"></a></span>
<span id="cb20-524"><a href="#cb20-524"></a><span class="ss">5. </span>Compute the uncentered EIF:</span>
<span id="cb20-525"><a href="#cb20-525"></a></span>
<span id="cb20-526"><a href="#cb20-526"></a>   <span class="in">```{r}</span></span>
<span id="cb20-527"><a href="#cb20-527"></a><span class="in">   eif &lt;- ip_weights * (y - b_pred) + (1 - a) / g0_pred * (pseudo - q_pred) +</span></span>
<span id="cb20-528"><a href="#cb20-528"></a><span class="in">     q_pred</span></span>
<span id="cb20-529"><a href="#cb20-529"></a><span class="in">   ```</span></span>
<span id="cb20-530"><a href="#cb20-530"></a></span>
<span id="cb20-531"><a href="#cb20-531"></a><span class="ss">6. </span>The one step estimator is the mean of the uncentered EIF</span>
<span id="cb20-532"><a href="#cb20-532"></a></span>
<span id="cb20-533"><a href="#cb20-533"></a>   <span class="in">```{r}</span></span>
<span id="cb20-534"><a href="#cb20-534"></a><span class="in">   ## One-step estimator</span></span>
<span id="cb20-535"><a href="#cb20-535"></a><span class="in">   mean(eif)</span></span>
<span id="cb20-536"><a href="#cb20-536"></a><span class="in">   ```</span></span>
<span id="cb20-537"><a href="#cb20-537"></a></span>
<span id="cb20-538"><a href="#cb20-538"></a><span class="fu">## Performance of the one-step estimator in a small simulation study</span></span>
<span id="cb20-539"><a href="#cb20-539"></a></span>
<span id="cb20-540"><a href="#cb20-540"></a>First, we create a wrapper around the estimator</span>
<span id="cb20-541"><a href="#cb20-541"></a></span>
<span id="cb20-544"><a href="#cb20-544"></a><span class="in">```{r}</span></span>
<span id="cb20-545"><a href="#cb20-545"></a>one_step <span class="ot">&lt;-</span> <span class="cf">function</span>(y, m, a, w) {</span>
<span id="cb20-546"><a href="#cb20-546"></a>  b_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> m<span class="sc">:</span>a <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb20-547"><a href="#cb20-547"></a>  e_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> m <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> m), <span class="at">family =</span> binomial)</span>
<span id="cb20-548"><a href="#cb20-548"></a>  g_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(a <span class="sc">~</span> w, <span class="at">family =</span> binomial)</span>
<span id="cb20-549"><a href="#cb20-549"></a>  g1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(g_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb20-550"><a href="#cb20-550"></a>  g0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> g1_pred</span>
<span id="cb20-551"><a href="#cb20-551"></a>  e1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(e_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb20-552"><a href="#cb20-552"></a>  e0_pred <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> e1_pred</span>
<span id="cb20-553"><a href="#cb20-553"></a>  b1_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb20-554"><a href="#cb20-554"></a>    b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">1</span>, m, w), <span class="at">type =</span> <span class="st">'response'</span></span>
<span id="cb20-555"><a href="#cb20-555"></a>  )</span>
<span id="cb20-556"><a href="#cb20-556"></a>  b0_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb20-557"><a href="#cb20-557"></a>    b_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, m, w), <span class="at">type =</span> <span class="st">'response'</span></span>
<span id="cb20-558"><a href="#cb20-558"></a>  )</span>
<span id="cb20-559"><a href="#cb20-559"></a>  b_pred  <span class="ot">&lt;-</span> <span class="fu">predict</span>(b_fit, <span class="at">type =</span> <span class="st">'response'</span>)</span>
<span id="cb20-560"><a href="#cb20-560"></a>  pseudo <span class="ot">&lt;-</span> b1_pred <span class="sc">-</span> b0_pred</span>
<span id="cb20-561"><a href="#cb20-561"></a>  q_fit <span class="ot">&lt;-</span> <span class="fu">gam</span>(pseudo <span class="sc">~</span> a <span class="sc">+</span> w <span class="sc">+</span> <span class="fu">s</span>(w, <span class="at">by =</span> a))</span>
<span id="cb20-562"><a href="#cb20-562"></a>  q_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(q_fit, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">a =</span> <span class="dv">0</span>, <span class="at">w =</span> w))</span>
<span id="cb20-563"><a href="#cb20-563"></a>  ip_weights <span class="ot">&lt;-</span> a <span class="sc">/</span> g0_pred <span class="sc">*</span> e0_pred <span class="sc">/</span> e1_pred <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred</span>
<span id="cb20-564"><a href="#cb20-564"></a>  eif <span class="ot">&lt;-</span> ip_weights <span class="sc">*</span> (y <span class="sc">-</span> b_pred) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> a) <span class="sc">/</span> g0_pred <span class="sc">*</span></span>
<span id="cb20-565"><a href="#cb20-565"></a>    (pseudo <span class="sc">-</span> q_pred) <span class="sc">+</span> q_pred</span>
<span id="cb20-566"><a href="#cb20-566"></a>  <span class="fu">return</span>(<span class="fu">mean</span>(eif))</span>
<span id="cb20-567"><a href="#cb20-567"></a>}</span>
<span id="cb20-568"><a href="#cb20-568"></a><span class="in">```</span></span>
<span id="cb20-569"><a href="#cb20-569"></a></span>
<span id="cb20-570"><a href="#cb20-570"></a>Let us first examine the bias</span>
<span id="cb20-571"><a href="#cb20-571"></a></span>
<span id="cb20-572"><a href="#cb20-572"></a><span class="ss">- </span>The true value is:</span>
<span id="cb20-573"><a href="#cb20-573"></a></span>
<span id="cb20-576"><a href="#cb20-576"></a><span class="in">```{r}</span></span>
<span id="cb20-577"><a href="#cb20-577"></a>w_big <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="fl">1e6</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-578"><a href="#cb20-578"></a>trueval <span class="ot">&lt;-</span> <span class="fu">mean</span>((<span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">1</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)</span>
<span id="cb20-579"><a href="#cb20-579"></a>  <span class="sc">+</span> (<span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">1</span>, w_big) <span class="sc">-</span> <span class="fu">mean_y</span>(<span class="dv">0</span>, <span class="dv">0</span>, w_big)) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="fu">mean_m</span>(<span class="dv">0</span>, w_big)))</span>
<span id="cb20-580"><a href="#cb20-580"></a><span class="fu">print</span>(trueval)</span>
<span id="cb20-581"><a href="#cb20-581"></a><span class="in">```</span></span>
<span id="cb20-582"><a href="#cb20-582"></a></span>
<span id="cb20-583"><a href="#cb20-583"></a><span class="ss">- </span>Bias simulation</span>
<span id="cb20-584"><a href="#cb20-584"></a></span>
<span id="cb20-587"><a href="#cb20-587"></a><span class="in">```{r}</span></span>
<span id="cb20-588"><a href="#cb20-588"></a>estimate <span class="ot">&lt;-</span> <span class="fu">lapply</span>(<span class="fu">seq_len</span>(<span class="dv">1000</span>), <span class="cf">function</span>(iter) {</span>
<span id="cb20-589"><a href="#cb20-589"></a>  n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb20-590"><a href="#cb20-590"></a>  w <span class="ot">&lt;-</span> <span class="fu">runif</span>(n, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb20-591"><a href="#cb20-591"></a>  a <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">pscore</span>(w))</span>
<span id="cb20-592"><a href="#cb20-592"></a>  m <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n, <span class="dv">1</span>, <span class="fu">mean_m</span>(a, w))</span>
<span id="cb20-593"><a href="#cb20-593"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="fu">mean_y</span>(m, a, w))</span>
<span id="cb20-594"><a href="#cb20-594"></a>  estimate <span class="ot">&lt;-</span> <span class="fu">one_step</span>(y, m, a, w)</span>
<span id="cb20-595"><a href="#cb20-595"></a>  <span class="fu">return</span>(estimate)</span>
<span id="cb20-596"><a href="#cb20-596"></a>})</span>
<span id="cb20-597"><a href="#cb20-597"></a>estimate <span class="ot">&lt;-</span> <span class="fu">do.call</span>(c, estimate)</span>
<span id="cb20-598"><a href="#cb20-598"></a></span>
<span id="cb20-599"><a href="#cb20-599"></a><span class="fu">hist</span>(estimate)</span>
<span id="cb20-600"><a href="#cb20-600"></a><span class="fu">abline</span>(<span class="at">v =</span> trueval, <span class="at">col =</span> <span class="st">"red"</span>, <span class="at">lwd =</span> <span class="dv">4</span>)</span>
<span id="cb20-601"><a href="#cb20-601"></a><span class="in">```</span></span>
<span id="cb20-602"><a href="#cb20-602"></a></span>
<span id="cb20-603"><a href="#cb20-603"></a><span class="ss">- </span>And now the confidence intervals:</span>
<span id="cb20-604"><a href="#cb20-604"></a></span>
<span id="cb20-607"><a href="#cb20-607"></a><span class="in">```{r}</span></span>
<span id="cb20-608"><a href="#cb20-608"></a><span class="co">#| fig-width: 8</span></span>
<span id="cb20-609"><a href="#cb20-609"></a>cis <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb20-610"><a href="#cb20-610"></a>  estimate <span class="sc">-</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate),</span>
<span id="cb20-611"><a href="#cb20-611"></a>  estimate <span class="sc">+</span> <span class="fu">qnorm</span>(<span class="fl">0.975</span>) <span class="sc">*</span> <span class="fu">sd</span>(estimate)</span>
<span id="cb20-612"><a href="#cb20-612"></a>)</span>
<span id="cb20-613"><a href="#cb20-613"></a></span>
<span id="cb20-614"><a href="#cb20-614"></a>ord <span class="ot">&lt;-</span> <span class="fu">order</span>(<span class="fu">rowSums</span>(cis))</span>
<span id="cb20-615"><a href="#cb20-615"></a>lower <span class="ot">&lt;-</span> cis[ord, <span class="dv">1</span>]</span>
<span id="cb20-616"><a href="#cb20-616"></a>upper <span class="ot">&lt;-</span> cis[ord, <span class="dv">2</span>]</span>
<span id="cb20-617"><a href="#cb20-617"></a><span class="fu">curve</span>(trueval <span class="sc">+</span> <span class="dv">0</span> <span class="sc">*</span> x,</span>
<span id="cb20-618"><a href="#cb20-618"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1001</span>), <span class="at">lwd =</span> <span class="dv">2</span>, <span class="at">lty =</span> <span class="dv">3</span>, <span class="at">xaxt =</span> <span class="st">"n"</span>,</span>
<span id="cb20-619"><a href="#cb20-619"></a>  <span class="at">xlab =</span> <span class="st">""</span>, <span class="at">ylab =</span> <span class="st">"Confidence interval"</span>, <span class="at">cex.axis =</span> <span class="fl">1.2</span>, <span class="at">cex.lab =</span> <span class="fl">1.2</span></span>
<span id="cb20-620"><a href="#cb20-620"></a>)</span>
<span id="cb20-621"><a href="#cb20-621"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>) {</span>
<span id="cb20-622"><a href="#cb20-622"></a>  clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="fl">0.5</span>, <span class="dv">0</span>, <span class="fl">0.75</span>, <span class="fl">0.5</span>)</span>
<span id="cb20-623"><a href="#cb20-623"></a>  <span class="cf">if</span> (upper[i] <span class="sc">&lt;</span> trueval <span class="sc">||</span> lower[i] <span class="sc">&gt;</span> trueval) clr <span class="ot">&lt;-</span> <span class="fu">rgb</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb20-624"><a href="#cb20-624"></a>  <span class="fu">points</span>(<span class="fu">rep</span>(i, <span class="dv">2</span>), <span class="fu">c</span>(lower[i], upper[i]), <span class="at">type =</span> <span class="st">"l"</span>, <span class="at">lty =</span> <span class="dv">1</span>, <span class="at">col =</span> clr)</span>
<span id="cb20-625"><a href="#cb20-625"></a>}</span>
<span id="cb20-626"><a href="#cb20-626"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.10</span>, <span class="st">"n=1000 repetitions = 1000 "</span>, <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb20-627"><a href="#cb20-627"></a><span class="fu">text</span>(<span class="dv">450</span>, <span class="fl">0.01</span>, <span class="fu">paste0</span>(</span>
<span id="cb20-628"><a href="#cb20-628"></a>  <span class="st">"Coverage probability = "</span>,</span>
<span id="cb20-629"><a href="#cb20-629"></a>  <span class="fu">mean</span>(lower <span class="sc">&lt;</span> trueval <span class="sc">&amp;</span> trueval <span class="sc">&lt;</span> upper), <span class="st">"%"</span></span>
<span id="cb20-630"><a href="#cb20-630"></a>), <span class="at">cex =</span> <span class="fl">1.2</span>)</span>
<span id="cb20-631"><a href="#cb20-631"></a><span class="in">```</span></span>
<span id="cb20-632"><a href="#cb20-632"></a></span>
<span id="cb20-633"><a href="#cb20-633"></a><span class="fu">## A note about targeted minimum loss-based estimation (TMLE)</span></span>
<span id="cb20-634"><a href="#cb20-634"></a></span>
<span id="cb20-635"><a href="#cb20-635"></a><span class="ss">- </span>The above estimator is great because it allows us to use data-adaptive</span>
<span id="cb20-636"><a href="#cb20-636"></a>  regression to avoid bias, while allowing the computation of correct standard</span>
<span id="cb20-637"><a href="#cb20-637"></a>  errors</span>
<span id="cb20-638"><a href="#cb20-638"></a><span class="ss">- </span>This estimator has a problem, though:</span>
<span id="cb20-639"><a href="#cb20-639"></a><span class="ss">  - </span>It can yield answers outside of the bounds of the parameter space</span>
<span id="cb20-640"><a href="#cb20-640"></a><span class="ss">  - </span>E.g., if $Y$ is binary, it could yield direct and indirect effects outside</span>
<span id="cb20-641"><a href="#cb20-641"></a>    of $<span class="co">[</span><span class="ot">-1,1</span><span class="co">]</span>$</span>
<span id="cb20-642"><a href="#cb20-642"></a><span class="ss">  - </span>To solve this, you can compute a TMLE instead (implemented in the R</span>
<span id="cb20-643"><a href="#cb20-643"></a>    packages, coming up)</span>
<span id="cb20-644"><a href="#cb20-644"></a></span>
<span id="cb20-645"><a href="#cb20-645"></a><span class="fu">## A note about cross-fitting</span></span>
<span id="cb20-646"><a href="#cb20-646"></a></span>
<span id="cb20-647"><a href="#cb20-647"></a><span class="ss">- </span>When using data-adaptive regression estimators, it is recommended to use</span>
<span id="cb20-648"><a href="#cb20-648"></a>  cross-fitted estimators</span>
<span id="cb20-649"><a href="#cb20-649"></a><span class="ss">- </span>Cross-fitting is similar to cross-validation:</span>
<span id="cb20-650"><a href="#cb20-650"></a><span class="ss">  - </span>Randomly split the sample into K (e.g., K=10) subsets of equal size</span>
<span id="cb20-651"><a href="#cb20-651"></a><span class="ss">  - </span>For each of the 9/10ths of the sample, fit the regression models</span>
<span id="cb20-652"><a href="#cb20-652"></a><span class="ss">  - </span>Use the out-of-sample fit to predict in the remaining 1/10th of the sample</span>
<span id="cb20-653"><a href="#cb20-653"></a><span class="ss">- </span>Cross-fitting further reduces the bias of the estimators</span>
<span id="cb20-654"><a href="#cb20-654"></a><span class="ss">- </span>Cross-fitting aids in guaranteeing the correctness of the standard errors and</span>
<span id="cb20-655"><a href="#cb20-655"></a>  confidence intervals</span>
<span id="cb20-656"><a href="#cb20-656"></a><span class="ss">- </span>Cross-fitting is implemented by default in the R packages that you will see</span>
<span id="cb20-657"><a href="#cb20-657"></a>  next</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/nhejazi/causal_mediation_workshops/edit/master/estimation_natural_interv.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/nhejazi/causal_mediation_workshops/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>